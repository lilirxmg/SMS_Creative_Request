{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Creative Request "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. API Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Pacakge  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import datetime as dt\n",
    "import filepath     \n",
    "import infrastructure\n",
    "import os \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import time \n",
    "import smartsheet\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:317: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID'] = mamba['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:95: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"lexi_original = infrastructure.get_lexi()\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:97: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"lexi = infrastructure.transform_sms_df(lexi)\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"# lexi.dropna(subset=['Hitpath Offer ID'], inplace = True)\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['eCPM'] = lexi['Revenue']*1000 / lexi['Delivered']\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['CTR'] = lexi['Clicks'] / lexi['Delivered']\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['Hitpath Offer ID'] = lexi['Hitpath Offer ID'].astype(str)\\n\",\n",
      "/opt/anaconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:317: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID'] = mamba['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:79: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:81: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"lexi['CTR'] = lexi['Clicks'] / lexi['Delivered']\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  },\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  {\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"cell_type\": \"code\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"execution_count\": 3,\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/TF_Content_Request_Report_SMS.ipynb:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"id\": \"89c746bb\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hitpath ID Request ID High Priority Submission Date  Due Date   \\\n",
      "0      13498                    False      2024-07-18 2024-07-23   \n",
      "1      13349                    False      2024-07-18 2024-07-23   \n",
      "2      11600                    False      2024-07-18 2024-07-23   \n",
      "3      12710                    False      2024-07-18 2024-07-23   \n",
      "4      13519                    False      2024-07-18 2024-07-23   \n",
      "\n",
      "  Request Sent to Copywriter (Kellie)  \\\n",
      "0                                       \n",
      "1                                       \n",
      "2                                       \n",
      "3                                       \n",
      "4                                       \n",
      "\n",
      "  Unapproved Content Document Link (Copywriter)  \\\n",
      "0                                                 \n",
      "1                                                 \n",
      "2                                                 \n",
      "3                                                 \n",
      "4                                                 \n",
      "\n",
      "  Unapproved Jump Page Content (Copywriter) Image ID - Jump Page (Copywriter)  \\\n",
      "0                                                                               \n",
      "1                                                                               \n",
      "2                                                                               \n",
      "3                                                                               \n",
      "4                                                                               \n",
      "\n",
      "  Request Type (Request)  ... Requested By              RX Rep  \\\n",
      "0                Content  ...       Script          Haley Bush   \n",
      "1                Content  ...       Script   Rhiannon Selander   \n",
      "2                Content  ...       Script       Hartley Goode   \n",
      "3                Content  ...       Script       Hartley Goode   \n",
      "4                Content  ...       Script  Jennifer Sporleder   \n",
      "\n",
      "                      External AM Email Channel Platform # of Shortcodes  \\\n",
      "0              kristine.o@point2web.com      TF       SS               5   \n",
      "1            taylor@interest-media.com       TF       SS               5   \n",
      "2      Mike - mike@whatifmediagroup.com      TF       SS               5   \n",
      "3      Mike - mike@whatifmediagroup.com      TF       SS               5   \n",
      "4  Ryan Zimmerman (ryan@avenuelink.com)      TF       SS               5   \n",
      "\n",
      "  Total Requests per Hitpath 30D Drop Count 90D Drop Count Priority Order  \n",
      "0                         10           34.0           37.0            3.0  \n",
      "1                         10           48.0           55.0            5.0  \n",
      "2                         10          248.0          629.0            6.5  \n",
      "3                         10          148.0          380.0            6.5  \n",
      "4                          5           25.0           28.0            8.0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# get all three report to see what we need request for SC,TF and Jump page  \n",
    "\n",
    "from ipynb.fs.full.Content_Request_Report_SMS import *\n",
    "from ipynb.fs.full.TF_Content_Request_Report_SMS import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Get Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file for SC Request \n",
    "save_path = filepath.output_folder + \"Content Request Reports\"\n",
    "sc_files = [f for f in listdir(save_path) if isfile(join(save_path, f)) & ('Content_Request_Report_' in f)]\n",
    "    #lexi_files = [f for f in listdir(lexi_download_path) if isfile(join(lexi_download_path, f)) \n",
    "        #              & ('Lexi 3.0' in f) & ~(\"Year\" in f)]\n",
    "\n",
    "sc_paths = [\"{}/{}\".format(save_path,sc_version) for sc_version in sc_files]\n",
    "times = [os.path.getmtime(path) for path in sc_paths]\n",
    "# times_formatted = [time.strftime('%m/%d/%Y %H:%M:%S', time.gmtime(time_float)) for time_float in times]\n",
    "most_recent_sc_request = sc_files[times.index(max(times))]\n",
    "sc_path = \"{}/{}\".format(save_path,most_recent_sc_request)\n",
    "# READ EXCEL AND GET THE SPECIFIC SHEET \n",
    "# Reading multiple sheets from an Excel file\n",
    "sc_request =  pd.read_excel(pd.ExcelFile(sc_path), sheet_name= 'Stats by Offer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file for TF Request \n",
    "save_path = filepath.output_folder + \"Content Request Reports\"\n",
    "sc_files = [f for f in listdir(save_path) if isfile(join(save_path, f)) & ('TF Content Request Report' in f)]\n",
    "\n",
    "sc_paths = [\"{}/{}\".format(save_path,sc_version) for sc_version in sc_files]\n",
    "times = [os.path.getmtime(path) for path in sc_paths]\n",
    "# times_formatted = [time.strftime('%m/%d/%Y %H:%M:%S', time.gmtime(time_float)) for time_float in times]\n",
    "most_recent_tf_request = sc_files[times.index(max(times))]\n",
    "tf_path = \"{}/{}\".format(save_path,most_recent_tf_request)\n",
    "tf_request =  pd.read_excel(pd.ExcelFile(tf_path), sheet_name= 'TF Content Requests')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get jump page report \n",
    "download_path = filepath.download_folder \n",
    "jp_files = [f for f in listdir(download_path) if isfile(join(download_path, f))& ('jump_page_feedback_reports' in f)]\n",
    "jp_paths = [\"{}/{}\".format(download_path,jp_version) for jp_version in jp_files]\n",
    "times = [os.path.getmtime(path) for path in jp_paths]\n",
    "times_formatted = [time.strftime('%m/%d/%Y %H:%M:%S', time.gmtime(time_float)) for time_float in times]\n",
    "most_recent_jp = jp_files[times.index(max(times))]\n",
    "jp_path = \"{}/{}\".format(download_path,most_recent_jp)\n",
    "jp_request =  pd.read_excel(pd.ExcelFile(jp_path), sheet_name= 'Need Request - Jump Page')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combine all Request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_15990/2954520889.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_request_simple.rename(columns = {'Priority Order':'SC Priority Order'}, inplace = True)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_15990/2954520889.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jp_request_simple['# of Pieces Requested Per Jump Page'] = 1\n"
     ]
    }
   ],
   "source": [
    "# get sc_request\n",
    "sc_request_simple = sc_request[['Hitpath Offer ID','Priority Order','# of Pieces Requested Per Shortcode','Shortcode Abbreviations','# of Shortcodes','Total Requests per Hitpath']]\n",
    "sc_request_simple.rename(columns = {'Priority Order':'SC Priority Order'}, inplace = True)\n",
    "# get tf_request \n",
    "request_tf = ['MFA', 'N3G', \"FRH\",'DA','TRS']\n",
    "tf_request['Toll Free Abbreviations'] = '\\n'.join(request_tf)\n",
    "tf_request['TF Priority Order'] = tf_request['CTR50'].rank(ascending=False)\n",
    "tf_request.rename({\"Pieces to Request\":\"# of Pieces Requested Per Toll Free\"}, axis = 1, inplace = True)\n",
    "tf_request['Total Requests per Toll Free'] = len(request_tf) * tf_request['# of Pieces Requested Per Toll Free']\n",
    "tf_request_simple = tf_request[['Hitpath Offer ID','Toll Free Abbreviations','TF Priority Order','# of Pieces Requested Per Toll Free','Total Requests per Toll Free']]\n",
    "# get jp_request \n",
    "jp_request['combine_index'] = jp_request['Text CTR'].rank(ascending = False) + jp_request['Jump Page Click Rate'].rank(ascending = True)\n",
    "jp_request['JP Prioirty Level'] = jp_request['combine_index'].rank(ascending = True)\n",
    "jp_request_simple = jp_request[['Hitpath Offer ID','JP Prioirty Level']]\n",
    "jp_request_simple['# of Pieces Requested Per Jump Page'] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_request = sc_request_simple.merge(tf_request_simple, on = 'Hitpath Offer ID', how = 'outer').merge(jp_request_simple, on = 'Hitpath Offer ID', how = 'outer')\n",
    "combined_request['SC Priority Order'] = combined_request['SC Priority Order'].fillna(combined_request['SC Priority Order'].max()+1)\n",
    "combined_request['TF Priority Order'] = combined_request['TF Priority Order'].fillna(combined_request['TF Priority Order'].max()+1)\n",
    "combined_request['JP Prioirty Level'] = combined_request['JP Prioirty Level'].fillna(combined_request['JP Prioirty Level'].max()+1)\n",
    "combined_request['score'] =combined_request['SC Priority Order']/combined_request['SC Priority Order'].max() * 0.4 + combined_request['TF Priority Order']/ combined_request['TF Priority Order'].max() * 0.3+ combined_request['JP Prioirty Level'] / combined_request['JP Prioirty Level'].max() * 0.3\n",
    "combined_request['Priority'] = combined_request['score'].rank(ascending = True)\n",
    "combined_request.drop(['score','JP Prioirty Level','TF Priority Order','SC Priority Order'], axis = 1, inplace = True)\n",
    "combined_request.sort_values(by = 'Priority', inplace = True)\n",
    "combined_request['Hitpath Offer ID'] = combined_request['Hitpath Offer ID'].astype(str).str.replace('.0','')\n",
    "combined_request['# of Pieces Requested Per Jump Page'] = combined_request['# of Pieces Requested Per Jump Page'].fillna(0)\n",
    "combined_request['# of Pieces Requested Per Toll Free'] = combined_request['# of Pieces Requested Per Toll Free'].fillna(0)  \n",
    "combined_request['# of Pieces Requested Per Shortcode'] = combined_request['# of Pieces Requested Per Shortcode'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find final request based on capacity and submit it to Smartsheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hitpath ID Request ID High Priority Submission Date  Due Date   \\\n",
      "0       8838                    False      2024-07-18 2024-07-23   \n",
      "1      13521                    False      2024-07-18 2024-07-23   \n",
      "2      13059                    False      2024-07-18 2024-07-23   \n",
      "3      13504                    False      2024-07-18 2024-07-23   \n",
      "4      11890                    False      2024-07-18 2024-07-23   \n",
      "5      13349                    False      2024-07-18 2024-07-23   \n",
      "6      13399                    False      2024-07-18 2024-07-23   \n",
      "7      12611                    False      2024-07-18 2024-07-23   \n",
      "8      12110                    False      2024-07-18 2024-07-23   \n",
      "9      13089                    False      2024-07-18 2024-07-23   \n",
      "\n",
      "  Request Sent to Copywriter (Kellie)  \\\n",
      "0                                       \n",
      "1                                       \n",
      "2                                       \n",
      "3                                       \n",
      "4                                       \n",
      "5                                       \n",
      "6                                       \n",
      "7                                       \n",
      "8                                       \n",
      "9                                       \n",
      "\n",
      "  Unapproved Content Document Link (Copywriter)  \\\n",
      "0                                                 \n",
      "1                                                 \n",
      "2                                                 \n",
      "3                                                 \n",
      "4                                                 \n",
      "5                                                 \n",
      "6                                                 \n",
      "7                                                 \n",
      "8                                                 \n",
      "9                                                 \n",
      "\n",
      "  Unapproved Jump Page Content (Copywriter) Image ID - Jump Page (Copywriter)  \\\n",
      "0                                                                               \n",
      "1                                                                               \n",
      "2                                                                               \n",
      "3                                                                               \n",
      "4                                                                               \n",
      "5                                                                               \n",
      "6                                                                               \n",
      "7                                                                               \n",
      "8                                                                               \n",
      "9                                                                               \n",
      "\n",
      "  Request Type (Request)  ...  \\\n",
      "0              Jump Page  ...   \n",
      "1              Jump Page  ...   \n",
      "2    Content & Jump Page  ...   \n",
      "3              Jump Page  ...   \n",
      "4              Jump Page  ...   \n",
      "5                Content  ...   \n",
      "6                Content  ...   \n",
      "7    Content & Jump Page  ...   \n",
      "8              Jump Page  ...   \n",
      "9    Content & Jump Page  ...   \n",
      "\n",
      "                                   External AM Email Channel Platform  \\\n",
      "0                                  Amber Paul-Ferris      SC       SS   \n",
      "1                       mike@legalclaimassistant.com      SC       SS   \n",
      "2                         Kara Moore kara@cx3ads.com      SC       SS   \n",
      "3                          jason@banneredgemedia.com      SC       SS   \n",
      "4  Patrick Welty, patrick@3westmedia.com - Andrew...      SC       SS   \n",
      "5                         taylor@interest-media.com   SC\\nTF       SS   \n",
      "6            Madison Housel - madison@btwodirect.com      SC       SS   \n",
      "7               Ryan Zimmerman (ryan@avenuelink.com)      SC       SS   \n",
      "8                         jenn@addictedaffiliate.com      SC       SS   \n",
      "9            Madison Housel - madison@btwodirect.com      SC       SS   \n",
      "\n",
      "  Total Requests per Hitpath Total Requests per Toll Free  \\\n",
      "0                        0.0                          0.0   \n",
      "1                        0.0                          0.0   \n",
      "2                       12.0                          0.0   \n",
      "3                        0.0                          0.0   \n",
      "4                        0.0                          0.0   \n",
      "5                       12.0                         10.0   \n",
      "6                        6.0                          0.0   \n",
      "7                        5.0                          0.0   \n",
      "8                        0.0                          0.0   \n",
      "9                        8.0                          0.0   \n",
      "\n",
      "  # of Pieces Requested Per Jump Page 30D Drop Count 90D Drop Count  \\\n",
      "0                                 1.0           47.0          126.0   \n",
      "1                                 1.0           10.0           10.0   \n",
      "2                                 1.0           86.0          181.0   \n",
      "3                                 1.0           21.0           24.0   \n",
      "4                                 1.0           33.0          113.0   \n",
      "5                                 0.0           48.0           55.0   \n",
      "6                                 0.0          150.0          208.0   \n",
      "7                                 1.0           60.0          151.0   \n",
      "8                                 1.0           32.0           47.0   \n",
      "9                                 1.0           32.0           68.0   \n",
      "\n",
      "  Priority Order Total Request  \n",
      "0            2.0           1.0  \n",
      "1            3.0           1.0  \n",
      "2            5.0          12.0  \n",
      "3            7.0           1.0  \n",
      "4           10.0           1.0  \n",
      "5           11.5          12.0  \n",
      "6           11.5           6.0  \n",
      "7           13.0           5.0  \n",
      "8           14.0           1.0  \n",
      "9           15.0           8.0  \n",
      "\n",
      "[10 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "submission_df = finalize_submission_all_df(combined_request)\n",
    "final_submission_df,stats_by_offer = make_pieces_request_all_df(submission_df, request_limit=50)\n",
    "#final_submission_df.drop(['Request Type (Request)','Compliance & Additional Notes (Request)'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_in_smartsheet(df, key, sheet_id):\n",
    "    \"\"\"\n",
    "    Writes a dataframe to a given smartsheet\n",
    "\n",
    "    :param df: a DataFrame whose column names match with columns in the given smartsheet\n",
    "    :param key: a string of the smartsheet API token\n",
    "    :param sheet_id: an int of the smartsheet sheet ID\n",
    "\n",
    "    :return: the result of placing into smartsheet. Use help() if you need to know more. \n",
    "             E.x. result = place_in_smartsheet(df, key, sheet_id) --> help(result)\n",
    "    \"\"\"\n",
    "    print('Adding Data to Smartsheet...')\n",
    "    am_contact_list = { 'Eamon McMahon':'e.mcmahon@rxmg.com' , 'Haley Bush':'h.bush@rxmg.com', 'Hartley Goode':'h.goode@rxmg.com', 'Jennifer Chatellier':'jennifer@rxmg.com', 'Jennifer Sporleder':'j.sporleder@rxmg.com', \n",
    "                   'Kelly baker':'kelly@rxmg.com', 'Marley Smith':'m.smith@rxmg.com', 'Mary Beth Howe':'m.howe@rxmg.com', 'Rhiannon Selander':'r.selander@rxmg.com', 'Sarah Bowe':'s.bowe@rxmg.com', 'Surya Hemanth':'s.hemanth@rxmg.com'}\n",
    "\n",
    "    smart = smartsheet.Smartsheet(key)\n",
    "    sheet = smart.Sheets.get_sheet(sheet_id)\n",
    "\n",
    "    # translate column names to column id\n",
    "    column_map = {}\n",
    "    for column in sheet.columns:\n",
    "        column_map[column.title] = (column.id, column.type)\n",
    "\n",
    "    data_dict = df.to_dict('index')\n",
    "\n",
    "    rows_list = []\n",
    "    for _, i in data_dict.items():\n",
    "        row = smart.models.Row()\n",
    "        row.to_bottom = True\n",
    "\n",
    "        for k, v in i.items():\n",
    "            cell = smart.models.Cell()\n",
    "            cell.column_id = column_map[k][0]\n",
    "            cell.column_type = str(column_map[k][1])\n",
    "            cell.object_value = v\n",
    "            if (k == 'RX Rep') &  (v in am_contact_list.keys()):\n",
    "                print(k,v,am_contact_list[v])\n",
    "                cell.object_value = {\n",
    "                    \"objectType\": \"CONTACT\",\n",
    "                    \"email\": am_contact_list[v],  \n",
    "                    \"name\": v\n",
    "                }\n",
    "                \n",
    "            row.cells.append(cell)\n",
    "            \n",
    "        \n",
    "        rows_list.append(row)\n",
    "        \n",
    "    result = smart.Sheets.add_rows(sheet_id, rows_list)\n",
    "\n",
    "    print('Data added to Smartsheet')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Data to Smartsheet...\n",
      "RX Rep Marley Smith m.smith@rxmg.com\n",
      "RX Rep Eamon McMahon e.mcmahon@rxmg.com\n",
      "RX Rep Mary Beth Howe m.howe@rxmg.com\n",
      "RX Rep Rhiannon Selander r.selander@rxmg.com\n",
      "RX Rep Sarah Bowe s.bowe@rxmg.com\n",
      "RX Rep Rhiannon Selander r.selander@rxmg.com\n",
      "RX Rep Hartley Goode h.goode@rxmg.com\n",
      "RX Rep Jennifer Sporleder j.sporleder@rxmg.com\n",
      "RX Rep Surya Hemanth s.hemanth@rxmg.com\n",
      "RX Rep Hartley Goode h.goode@rxmg.com\n",
      "Data added to Smartsheet\n"
     ]
    }
   ],
   "source": [
    "# API info to connect SMS Creative Smartsheet \n",
    "#sheet_id = 8253683024220036 # real sheet id \n",
    "sheet_id = 5426394364333956 # test sheet id \n",
    "#key = '7fQH9Go8sf6CruwY3g4HHzKHe6wFMzNbgyAYy' # back up key\n",
    "key = 'wf3Jr9OaAT5OE8gE8yctPqfmzrv6dUFATUODD'\n",
    "result = place_in_smartsheet(final_submission_df, key, sheet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Send email to the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update content request report \n",
    "\n",
    "with pd.ExcelWriter(sc_path, mode='a', if_sheet_exists='replace',engine='openpyxl') as writer:\n",
    "    stats_by_offer.to_excel(writer, sheet_name='Stats by Offer', index=False)\n",
    "with pd.ExcelWriter(sc_path, mode='a', if_sheet_exists='replace',engine='openpyxl') as writer:\n",
    "    final_submission_df.to_excel(writer, sheet_name='Content Requests', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import flatten\n",
    "from openpyxl.styles import numbers\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Color, colors, fills\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from openpyxl.styles.borders import Border, Side, BORDER_THIN\n",
    "thin_border = Border(\n",
    "    left=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    right=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    top=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    bottom=Side(border_style=BORDER_THIN, color='D3D3D3')\n",
    ")\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Recently Tested Content Report\n",
    "\n",
    "submission_df_hitpaths = final_submission_df['Hitpath Offer ID'].tolist()\n",
    "submission_df_hitpaths = [str(x) for x in submission_df_hitpaths]\n",
    "stats_by_offer_hitpaths = stats_by_offer['Hitpath Offer ID'].tolist()\n",
    "stats_by_offer_hitpaths = [str(x) for x in stats_by_offer_hitpaths]\n",
    "hitpath_requests_removed = [hitpath for hitpath in stats_by_offer_hitpaths if hitpath not in submission_df_hitpaths]\n",
    "\n",
    "# Load the workbook and the sheet\n",
    "workbook = load_workbook(sc_path)\n",
    "stats_by_offer_sheet = workbook['Stats by Offer']\n",
    "content_request_sheet = workbook['Content Requests']\n",
    "ws_headers = {}\n",
    "ws_headers['Stats by Offer'] = stats_by_offer.columns.tolist()\n",
    "ws_headers['Content Requests'] = final_submission_df.columns.tolist()\n",
    "currency_format_cols = ['Revenue', 'eCPM', 'eCPM_min_target']\n",
    "percent_format_cols = ['OOR', 'CTR', 'CTR_min_target', '30:90 Ratio']\n",
    "comma_format_cols = ['Optout', 'Clicks', 'Delivered']\n",
    "\n",
    "# Make entire row orange if offer was removed from requests\n",
    "for row in stats_by_offer_sheet.iter_rows(min_row=2):\n",
    "    # If the Sendable column if False, make entire row orange\n",
    "    if row[ws_headers['Stats by Offer'].index('Hitpath Offer ID')].value in hitpath_requests_removed:\n",
    "        for cell in row:     \n",
    "            cell.fill = fills.PatternFill(patternType='solid', fgColor=Color(rgb='fce5cd'))\n",
    "            cell.border = thin_border\n",
    "for ws in [stats_by_offer_sheet,content_request_sheet]:\n",
    "    dims = {}\n",
    "    headers = ws_headers[ws.title]\n",
    "\n",
    "    for row in ws.rows:\n",
    "        for cell in ws[\"1:1\"]:\n",
    "            cell.font = Font(bold=True)\n",
    "        for cell in row:\n",
    "            newline_count = 1\n",
    "            if cell.value:\n",
    "                if type(cell.value)==str:\n",
    "                    if ('\\n' in cell.value):\n",
    "                        newline_count = cell.value.count('\\n')\n",
    "                dims[cell.column_letter] = max((dims.get(cell.column_letter, 0), len(str(cell.value))))/newline_count \n",
    "    for col, value in dims.items():\n",
    "        ws.column_dimensions[col].width = value\n",
    "    for col in currency_format_cols:\n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_CURRENCY_USD_SIMPLE\n",
    "\n",
    "    for col in percent_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_PERCENTAGE_00\n",
    "\n",
    "    for col in comma_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = '#,##0'\n",
    "workbook.save(sc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Team,\n",
      "\n",
      "Please find this week's Content Request Report attached.\n",
      "\n",
      "The following AMs have offer content that was requested:\n",
      "\tHartley Goode: 1 offer\n",
      "\tMary Beth Howe: 1 offer\n",
      "\n",
      "Thanks,\n",
      "Lili Guo\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comment by Lili on 7/12\n",
    "#email\n",
    "\n",
    "toaddr = ['offernotices@rxmg.com', 'nathan@rxmg.com','nina@rxmg.com', 'k.smith@rxmg.com', 'a.miller@rxmg.com',  'lili@rxmg.com', 'r.woodward@rxmg.com', 'b.ratzlaff@rxmg.com']\n",
    "toaddr = ['lili@rxmg.com']\n",
    "subject_line = f\"SMS Content Request Report - {today}\"\n",
    "email_body = \"Hi Team,\\n\\n\"\n",
    "email_body += \"Please find this week's Content Request Report attached.\\n\\n\" \n",
    "email_body += \"The following AMs have offer content that was requested:\\n\" \n",
    "for key, value in rx_rep_offer_dict.items():\n",
    "    if value == 1:\n",
    "        email_body += f\"\\t{key}: {value} offer\\n\"\n",
    "    else:\n",
    "        email_body += f\"\\t{key}: {value} offers\\n\"\n",
    "email_body += f\"\\nThanks,\\n{filepath.name}\\n\\n\"\n",
    "print(email_body)\n",
    "#send email\n",
    "for i in toaddr:\n",
    "    send_email.send_email([sc_path], subject_line, email_body, i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
