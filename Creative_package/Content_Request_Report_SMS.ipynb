{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ea257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsheets import Sheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "# import filepaths\n",
    "# import content_feedback_report\n",
    "# import schedule_methods\n",
    "# import lexi_cobra_sync\n",
    "import pygsheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "# import schedule_methods\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import emoji\n",
    "import re\n",
    "import warnings\n",
    "import statistics\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import infrastructure \n",
    "from calendar import monthrange\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import xlsxwriter\n",
    "import send_email\n",
    "from colorama import Fore, Style\n",
    "import filepath\n",
    "import smartsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a84f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smartsheet API token\n",
    "key = 'gMX4xu48SUIH7rMEj4iaj7rIsQJ2ERbmgiYMJ'\n",
    "key = 'wf3Jr9OaAT5OE8gE8yctPqfmzrv6dUFATUODD'\n",
    "# SMS Creative Submission sheet ID\n",
    "# sheet_id = 2525300306956164 #FAKE SHEET\n",
    "#sheet_id = 8253683024220036 #REAL SHEET\n",
    "sheet_id = 5426394364333956"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08099154",
   "metadata": {},
   "source": [
    "# Downloading Lexi, Offers, CW, CT, and Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d38a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/3359913376.py:1: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lexi_original = pd.read_csv(filepath.input_folder + 'SS_LC_merged_data.csv')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID'] = mamba['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n"
     ]
    }
   ],
   "source": [
    "lexi_original = infrastructure.get_lexi()\n",
    "lexi = lexi_original.copy()\n",
    "lexi = infrastructure.transform_sms_df(lexi)\n",
    "lexi = lexi[lexi['Delivered'] > 0]\n",
    "# lexi[['Hitpath Offer ID']] = lexi[['Hitpath Offer ID']].apply(pd.to_numeric, errors='coerce')\n",
    "# lexi.dropna(subset=['Hitpath Offer ID'], inplace = True)\n",
    "\n",
    "lexi['eCPM'] = lexi['Revenue']*1000 / lexi['Delivered']\n",
    "lexi['CTR'] = lexi['Clicks'] / lexi['Delivered']\n",
    "lexi['Hitpath Offer ID'] = lexi['Hitpath Offer ID'].astype(str)\n",
    "lexi['Hitpath Offer ID'] = lexi['Hitpath Offer ID'].str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c746bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = infrastructure.get_lanina()\n",
    "cw.dropna(subset=['Reporting Content ID'],inplace=True)\n",
    "# cw[['OfferIDs']] = cw[['OfferIDs']].apply(pd.to_numeric, errors='coerce')\n",
    "cw.dropna(subset=['OfferIDs'], inplace = True)\n",
    "mask = cw['Type (Pitch)'] == 'HOL'\n",
    "cw = cw[~mask]\n",
    "cw['Allocation Period (Date Added)'] = pd.to_datetime(cw['Allocation Period (Date Added)'], format='mixed')\n",
    "cw.dropna(subset=['Reporting Content ID'],inplace=True)\n",
    "cw['OfferIDs'] = cw['OfferIDs'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a67862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_original = infrastructure.get_smartsheet('offers_sms')\n",
    "offers = offers_original.copy()\n",
    "offers.dropna(subset=['Hitpath Offer ID'],inplace=True)\n",
    "offers['Hitpath Offer ID'] = offers['Hitpath Offer ID'].astype(int).astype(str)\n",
    "offers.rename(columns={'Redirect Link (Ops will update when setup)':'Redirect Link'}, inplace=True)\n",
    "# offers['Hitpath Offer ID'] = offers['Hitpath Offer ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712e1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow = infrastructure.get_smartsheet('ow_sms')\n",
    "ow['Available Shortcode'] = ow['Available Shortcode'].apply(lambda x: x.split('\\n'))\n",
    "ow_status_dict = ow.set_index('Hitpath Offer ID')['Status'].to_dict()\n",
    "live_ow_shortcodes_dict = ow[ow['Status']=='Live'].set_index('Hitpath Offer ID')['Available Shortcode'].to_dict()\n",
    "not_live_ows = ow[~(ow['Status']=='Live')]['Hitpath Offer ID'].unique().tolist()\n",
    "ow_hitpath_list = ow['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53b88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexi = lexi.sort_values(by='Date')\n",
    "\n",
    "lexi_30 = lexi[(lexi['Date'].dt.date >= (date.today() + timedelta(days=-30)))].copy()\n",
    "lexi_90 = lexi[(lexi['Date'].dt.date >= (date.today() + timedelta(days=-90)))].copy()\n",
    "# Will use this list of hitpaths to consider for content requests--Production offers sending in the past 30 days\n",
    "eligible_hitpaths = lexi_30[lexi_30['Send Strategy']=='P']['Hitpath Offer ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495675fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/3074324814.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ct['Submission Date'] = pd.to_datetime(ct['Submission Date'])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/3074324814.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ct['Date Added to La Nina (Akshad)'] = pd.to_datetime(ct['Date Added to La Nina (Akshad)'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "ct =infrastructure.get_smartsheet('content_sms')\n",
    "ct['Submission Date'] = pd.to_datetime(ct['Submission Date'])\n",
    "ct['Date Added to La Nina (Akshad)'].replace(to_replace=r\"[a-zA-Z- ()]\", value=\"\", regex=True, inplace=True)\n",
    "ct['Date Added to La Nina (Akshad)'] = pd.to_datetime(ct['Date Added to La Nina (Akshad)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a84196a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/2744609448.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID']=mamba['Dataset'].str.split('_').str[2]\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/2744609448.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba[['Limit','Offset']] = mamba[['Limit','Offset']].fillna(\"\")\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/2744609448.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Drop Number'] = mamba['Drop'].str.split(expand=True)[1].astype(int)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/2744609448.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Day of Week'] = mamba['Date'].dt.dayofweek\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_20628/2744609448.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba.rename(columns={\"Segment \": \"Segment\"},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "mamba = infrastructure.get_mamba()\n",
    "mamba['Affiliate ID']=mamba['Dataset'].str.split('_').str[2]\n",
    "mamba[['Limit','Offset']] = mamba[['Limit','Offset']].fillna(\"\")\n",
    "mamba['Drop Number'] = mamba['Drop'].str.split(expand=True)[1].astype(int)\n",
    "mamba['Day of Week'] = mamba['Date'].dt.dayofweek\n",
    "mamba.rename(columns={\"Segment \": \"Segment\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056a01d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e066da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptable_performance(row):\n",
    "    \"\"\"\n",
    "    Determines if a given creative meets performance benchmarks for sending\n",
    "\n",
    "    :param row: a row of a dataframe (Series) that has columns 'CTR', 'CTR_min_target', 'eCPM', and 'eCPM_min_target'\n",
    "                The dataframe should contain information about a given creative relative to a benchmark\n",
    "    :return: True if given creative passes benchmarks. False if creative fails benchmarks\n",
    "    \"\"\"\n",
    "    if row['OOR'] >= 0.02:\n",
    "        return False\n",
    "    elif row['Num_Drops'] > 2:\n",
    "        if (row['CTR'] < row['CTR_min_target']) & (row['eCPM'] < row['eCPM_min_target']):\n",
    "            return False\n",
    "    elif (row['Shortcode Name'] == 'DSS') and (row['Num_Drops'] > 1):\n",
    "        if (row['CTR'] < row['CTR_min_target']) & (row['eCPM'] < row['eCPM_min_target']):\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e87f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shortcode_ctr_benchmark(row):\n",
    "    \n",
    "    # Noticed that DSS was performing worse with CTR, so want to lower the threshold for requesting more content\n",
    "    if row['Shortcode Name'] == 'DSS':\n",
    "        benchmark = row['CTR_mean'] - (0.5 * row['CTR_std'])\n",
    "    else:\n",
    "        benchmark = row['CTR_mean'] - row['CTR_std']\n",
    "\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc7b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stats_by_creative(min_eCPM_target=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param min_eCPM_target: An int of the minimum eCPM a content piece should generate to be considered 'sendworthy'.\n",
    "                            Default is $10\n",
    "    :return: A dictionary that has keys of (Shortcode Name, Hitpath Offer ID) and values of ints which are the\n",
    "            number of creatives per Shortcode/Hitpath ID combo that are bad.\n",
    "    \"\"\"\n",
    "    # Get Num_drops, OOR, CTR, and eCPM stats for each creative\n",
    "    stats_by_creative = lexi_30.groupby('Creative Type').agg(Optout=('Optout', 'sum'), Clicks=('Clicks', 'sum'), Revenue=('Revenue', 'sum'), Delivered=('Delivered', 'sum'), Shortcode_Name=('Shortcode Name', lambda x: x.value_counts().idxmax()), Hitpath_Offer_ID=('Hitpath Offer ID', lambda x: x.value_counts().idxmax()), \n",
    "                                                         Num_Drops=('Date', 'count'))\n",
    "    stats_by_creative = stats_by_creative.rename(columns={'Shortcode_Name':'Shortcode Name', 'Hitpath_Offer_ID':'Hitpath Offer ID'})\n",
    "\n",
    "    stats_by_creative['OOR'] = stats_by_creative['Optout'] / stats_by_creative['Delivered']\n",
    "    stats_by_creative['CTR'] = stats_by_creative['Clicks'] / stats_by_creative['Delivered']\n",
    "    stats_by_creative['eCPM'] = 1000 * stats_by_creative['Revenue'] / stats_by_creative['Delivered']\n",
    "    stats_by_creative = stats_by_creative.reset_index()\n",
    "\n",
    "    # Get 30d stats by shortcode as benchmark to compare to\n",
    "    stats_by_shortcode_30d = lexi_30.groupby('Shortcode Name').agg(CTR_mean=('CTR', 'mean'), CTR_std=('CTR', 'std')).reset_index()\n",
    "    stats_by_shortcode_30d['CTR_min_target'] = stats_by_shortcode_30d.apply(make_shortcode_ctr_benchmark, axis=1)\n",
    "#     stats_by_shortcode_30d['CTR_min_target'] = stats_by_shortcode_30d['CTR_mean'] - stats_by_shortcode_30d['CTR_std']\n",
    "    stats_by_shortcode_30d = stats_by_shortcode_30d[['Shortcode Name', 'CTR_min_target']]\n",
    "    stats_by_shortcode_30d['eCPM_min_target'] = min_eCPM_target\n",
    "\n",
    "    # Merge creative stats with benchmarks\n",
    "    stats_comparison = stats_by_creative.merge(stats_by_shortcode_30d, how='left', on='Shortcode Name')\n",
    "\n",
    "    # True if beats benchmarks, else False\n",
    "    stats_comparison['Sendable'] = stats_comparison.apply(lambda x: acceptable_performance(x), axis=1)\n",
    "\n",
    "    stats_comparison = stats_comparison[['Creative Type', 'Optout', 'Clicks', 'Revenue', 'Delivered', 'Shortcode Name', 'Hitpath Offer ID', \n",
    "                                         'Num_Drops', 'OOR', 'CTR', 'CTR_min_target', 'eCPM', 'eCPM_min_target', 'Sendable']]\n",
    "    stats_comparison['Hitpath Offer ID'] = stats_comparison['Hitpath Offer ID'].astype(str)\n",
    "\n",
    "    # Filter for only bad creatives\n",
    "    bad_creatives_df = stats_comparison[~stats_comparison['Sendable']]\n",
    "    bad_creatives_df = bad_creatives_df[['Hitpath Offer ID', 'Shortcode Name', 'Creative Type', 'Num_Drops', 'OOR', 'CTR', 'eCPM']]\n",
    "\n",
    "    # Create dict with keys of (SC Name, Hit ID) and values of number of bad content pieces\n",
    "    bad_offers_dict = bad_creatives_df.groupby(['Shortcode Name', 'Hitpath Offer ID'])['Creative Type'].count().to_dict()\n",
    "\n",
    "    return stats_comparison, bad_offers_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf50cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stats_by_offer(hitpath_id_list):\n",
    "    \"\"\"\n",
    "    \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Get Num_drops, OOR, CTR, and eCPM stats for each creative\n",
    "    stats_by_offer = lexi_30[lexi_30['Hitpath Offer ID'].isin(hitpath_id_list)].groupby(['Hitpath Offer ID']).agg(Optout=('Optout', 'sum'), Clicks=('Clicks', 'sum'), Revenue=('Revenue', 'sum'), Delivered=('Delivered', 'sum'), Num_Drops=('Date', 'count'))\n",
    "\n",
    "    stats_by_offer['OOR'] = stats_by_offer['Optout'] / stats_by_offer['Delivered']\n",
    "    stats_by_offer['CTR'] = stats_by_offer['Clicks'] / stats_by_offer['Delivered']\n",
    "    stats_by_offer['eCPM'] = 1000 * stats_by_offer['Revenue'] / stats_by_offer['Delivered']\n",
    "    stats_by_offer = stats_by_offer.reset_index()\n",
    "\n",
    "    # Lower rank is better\n",
    "    higher_good_ranks = stats_by_offer[['CTR', 'eCPM']].rank(ascending=False)\n",
    "    higher_bad_ranks = stats_by_offer[['OOR']].rank(ascending=True)\n",
    "\n",
    "    # Merge ranks onto df\n",
    "    stats_by_offer = pd.concat([stats_by_offer, higher_good_ranks.add_suffix('_rank')], axis=1)\n",
    "    stats_by_offer = pd.concat([stats_by_offer, higher_bad_ranks.add_suffix('_rank')], axis=1)\n",
    "\n",
    "\n",
    "    # Determine priority order based on sum of stat ranks\n",
    "    stats_by_offer['Priority Order'] = stats_by_offer['OOR_rank'] + stats_by_offer['CTR_rank'] + stats_by_offer['eCPM_rank']\n",
    "    stats_by_offer['Priority Order'] = stats_by_offer['Priority Order'].rank(ascending=False)\n",
    "    stats_by_offer = stats_by_offer.sort_values(by='Priority Order')\n",
    "    stats_by_offer['Hitpath Offer ID'] = stats_by_offer['Hitpath Offer ID'].astype(str)\n",
    "    stats_by_offer = stats_by_offer.rename(columns={'Num_Drops':'30D Drop Count'})\n",
    "    priority_dict = stats_by_offer.set_index(['Hitpath Offer ID'])['Priority Order'].to_dict()\n",
    "\n",
    "    return stats_by_offer, priority_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1fea6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_offer_count(row, bad_offers_dict):\n",
    "    \"\"\"\n",
    "    :return: an int of the number of bad creatives for each (Shortcode Name, Hitpath Offer ID) combo\n",
    "    \"\"\"\n",
    "    key = (row['Shortcode Name'], row['Hitpath Offer ID'])\n",
    "    return bad_offers_dict.get(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867bd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_already_requested_content():\n",
    "    \"\"\"\n",
    "    :return: a list of Hitpath Offer IDs that have had content requested within the past 2 weeks in the \n",
    "            SMS Creative Submission smartsheet.\n",
    "    \"\"\"\n",
    "    already_requested_content = ct.copy()\n",
    "    already_requested_content = already_requested_content[['Submission Date', 'Date Added to La Nina (Akshad)', '# of Pieces Requested Per Shortcode', 'Hitpath Offer ID', 'Request Type (Request)']]\n",
    "    already_requested_content = already_requested_content[already_requested_content['Request Type (Request)'].str.contains('Content', na=False)]\n",
    "    already_requested_content = already_requested_content[already_requested_content['# of Pieces Requested Per Shortcode']>0]\n",
    "    # Any offer without a date in this column has not been added to La Nina, and should not be requested again\n",
    "    already_requested_content = already_requested_content[((pd.isna(already_requested_content['Date Added to La Nina (Akshad)']))&(already_requested_content['Submission Date']>=pd.Timestamp(date.today()-timedelta(30)))) | \n",
    "                                                          (already_requested_content['Date Added to La Nina (Akshad)']>=pd.Timestamp(date.today() - timedelta(21)))]\n",
    "    # already_requested_content['Shortcode'] = already_requested_content['Shortcode'].apply(lambda x: x.split('\\n'))\n",
    "#     already_requested_content['Date Added to La Nina (Akshad)'] = already_requested_content['Date Added to La Nina (Akshad)'].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "#     already_requested_content = already_requested_content.dropna(subset=['Date Added to La Nina (Akshad)'])\n",
    "\n",
    "    return already_requested_content['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dbf926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_days_from_date(start_date, n):\n",
    "    \"\"\"\n",
    "    Returns the date of the business day that is n days from the start_date\n",
    "\n",
    "    :param start_date: a Timestamp of the first date to consider\n",
    "    :param n: an int of the number of business days ahead to return\n",
    "    :return: a Timestamp of the business day that is n days ahead of start_date\n",
    "    \"\"\"\n",
    "    current_date = start_date\n",
    "    while n > 0:\n",
    "        current_date += timedelta(days=1)\n",
    "        if current_date.weekday() < 5:  # Check if it's a weekday (Monday to Friday)\n",
    "            n -= 1\n",
    "    return current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5288bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advertiser_emails_dict():\n",
    "    \"\"\"\n",
    "    :return: a dictionary with keys of Advertiser Name and values of a list of\n",
    "            potential email addresses for that advertiser\n",
    "    \"\"\"\n",
    "    adv_emails = offers_original[(~pd.isna(offers_original['Advertiser'])) & (pd.isna(offers_original['Hitpath Offer ID']))][['Advertiser Rep', 'Advertiser']]\n",
    "    adv_emails = adv_emails.drop_duplicates(subset='Advertiser', keep='first')\n",
    "    adv_emails = adv_emails.fillna('')\n",
    "    adv_emails['Advertiser Rep'] = adv_emails['Advertiser Rep'].apply(lambda x: x.split('\\n'))\n",
    "    adv_emails = adv_emails.set_index('Advertiser')['Advertiser Rep'].to_dict()\n",
    "    \n",
    "    return adv_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9936db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "\n",
    "# def find_closest_email(name, email_list):\n",
    "#     email_score = 0\n",
    "#     closest_email = ''\n",
    "#     for email in email_list:\n",
    "#         email_name = email.split('@')[0]\n",
    "#         similarity_score = fuzz.token_sort_ratio(name, email_name)\n",
    "#         if similarity_score > email_score: \n",
    "#             closest_email = email\n",
    "    \n",
    "#     return closest_email\n",
    "\n",
    "def find_closest_email(name, email_list):\n",
    "    \"\"\"\n",
    "    Takes a name and compares it to a list of email addresses to find the email addresss that\n",
    "    most closely matches. \n",
    "\n",
    "    :param name: a string of a name\n",
    "    :param email_list: a list of strings of potential emails\n",
    "    :return: a string of the email that most closely matches the name given.\n",
    "            If none of the emails make sense, returns a blank string\n",
    "    \"\"\"\n",
    "    # If first and last name are listed, will see if either are in the email address\n",
    "    for name_part in name.split():\n",
    "        for email in email_list:\n",
    "            if not '@' in email:\n",
    "                continue\n",
    "            email_name = email.split('@')[0].lower()\n",
    "            if name_part.lower() in email_name:\n",
    "                return email\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "028346c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advertiser_email_address(row):\n",
    "    \"\"\"\n",
    "    For a given Advertiser/Advertiser Rep combo, finds the email from possible Advertiser emails\n",
    "    that most closely matches with the Advertiser Rep.\n",
    "\n",
    "    :param row: a row of a dataframe (Series) with columns of 'Advertiser Rep', and 'Advertiser'\n",
    "    :return: a string of an email address\n",
    "    \"\"\"\n",
    "    # If it is an OW, there are many different advertisers, so no email is listed\n",
    "    if row['Hitpath Offer ID'] in ow_hitpath_list:\n",
    "        return ''\n",
    "    # Get dict mapping Advertiser to email list\n",
    "    adv_emails = get_advertiser_emails_dict()\n",
    "    \n",
    "    # If Advertiser Rep already has an email listed, use that\n",
    "    if '@' in row['Advertiser Rep']:\n",
    "        return row['Advertiser Rep']\n",
    "    else:\n",
    "        possible_emails = adv_emails[row['Advertiser']]\n",
    "        name = row['Advertiser Rep']\n",
    "        closest_email = find_closest_email(name, possible_emails)\n",
    "\n",
    "        # If not emails match, use the Advertiser Rep as the email\n",
    "        if not closest_email:\n",
    "            closest_email = row['Advertiser Rep']\n",
    "\n",
    "        # If the Advertiser Rep is blank, use the Advertiser\n",
    "        if not closest_email:\n",
    "            closest_email = adv_emails[row['Advertiser']]\n",
    "        \n",
    "        # If the Advertiser is blank, leave blank\n",
    "        if closest_email == ['']:\n",
    "            closest_email = ''\n",
    "        \n",
    "        # If closest email is still a list, use all contents of list, separated by a dash if multiple elements\n",
    "        if type(closest_email) == list:\n",
    "            if len(closest_email) == 1:\n",
    "                closest_email = closest_email[0]\n",
    "            else:\n",
    "                closest_email = ' - '.join(closest_email)\n",
    "    \n",
    "    return closest_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9afbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_approval_status(status):\n",
    "    \"\"\"\n",
    "    Fix formatting of Custom Creative Allowed and default to Required\n",
    "    \n",
    "    :param status: a string from Custom Creative Allowed column in smartsheet\n",
    "    :return: a string that is formatted the same as seen in SMS Creative Submission with options being\n",
    "            Required or Not Required. Default to Required\n",
    "    \"\"\"\n",
    "    if pd.isna(status):\n",
    "        status = 'Required'\n",
    "    elif status == 'NOT Required':\n",
    "        status = 'Not Required'\n",
    "    elif 'Approved' in status:\n",
    "        status = 'Required'\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28463c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_ID_number():\n",
    "    \"\"\"\n",
    "    :return: an int of 1 more than the maximum request ID number from the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    # Pull number from Request ID\n",
    "    ID_numbers = [int(re.search(r'\\.(\\d+)\\.', s).group(1)) for s in ct['Request ID']]\n",
    "\n",
    "    # Starting Request ID is 1 more than maximum\n",
    "    return max(ID_numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73e3681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def find_closest_RX_Rep(name):\n",
    "    \"\"\"\n",
    "    Takes a name and compares it to a list of RX_Reps to find the RX_Rep that\n",
    "    most closely matches. \n",
    "\n",
    "    :param name: a string of a name\n",
    "    :return: a string of the RX_Rep that most closely matches the name given.\n",
    "            If none of the RX_Reps make sense, returns a blank string\n",
    "    \"\"\"\n",
    "    if pd.isna(name) or name=='' or name.lower()=='nan':\n",
    "        return ''\n",
    "    RX_Rep_list = ['Eamon McMahon', 'Haley Bush', 'Hartley Goode', 'Jennifer Chatellier', 'Jennifer Sporleder', \n",
    "                   'Kelly baker', 'Marley Smith', 'Mary Beth Howe', 'Rhiannon Selander', 'Sarah Bowe', 'Surya Hemanth']\n",
    "    RX_Rep_score = 0\n",
    "    closest_RX_Rep = ''\n",
    "    for RX_Rep in RX_Rep_list:\n",
    "        similarity_score = fuzz.token_sort_ratio(name, RX_Rep)\n",
    "        if similarity_score > RX_Rep_score: \n",
    "            closest_RX_Rep = RX_Rep\n",
    "            RX_Rep_score = similarity_score\n",
    "    \n",
    "    return closest_RX_Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbfcb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_requests_per_shortcode(requests_per_shortcode, limit=2):\n",
    "    \"\"\"Bring any requests per shortcode above the limit down to the limit\"\"\"\n",
    "\n",
    "    if requests_per_shortcode > limit:\n",
    "        return limit\n",
    "    else:\n",
    "        return requests_per_shortcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5d11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_submission_df(df):\n",
    "    \"\"\"\n",
    "    Properly formats the dataframe containing info on # of Pieces needed to be requested so that it can be pasted into\n",
    "    the SMS Creative Submission smartsheet. Also, gathers any additional information needed.\n",
    "\n",
    "    :param df: a dataframe of the # of pieces needed to be requested for each Shortcode/Hitpath ID combo\n",
    "    :return: a dataframe that is ready to be pasted into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    ct_columns = ['Hitpath ID', 'Request ID', 'High Priority', 'Submission Date',\n",
    "    'Due Date ', 'Request Sent to Copywriter (Kellie)', 'Unapproved Content Document Link (Copywriter)',\n",
    "    'Unapproved Jump Page Content (Copywriter)', 'Image ID - Jump Page (Copywriter)', 'Request Type (Request)',\n",
    "    'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    'Jump Page Link (Akshad)', 'Creative Approval Status', 'Date - Content sent for approval to network (K.S.)',\n",
    "    'Date Got Approval from Advertiser (K.S.)', 'Approved Jump Page Link (Kellie)', 'External - Approved Content Document (Kellie)',\n",
    "    'Ready for Akshad (Kellie Checks; Alert Sent)', 'Date Added to La Nina (Akshad)', 'Offer Type', 'Operational Status (Connected to SMS-OMA)',\n",
    "    'Hitpath Offer ID', 'Offer Name', 'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Toll Free Abbreviations', 'Requested By', \n",
    "    'RX Rep', 'External AM Email', 'Channel', 'Platform']\n",
    "\n",
    "    # date_columns = ['Submission Date', 'Due Date ', 'Request Sent to Copywriter (Kellie)',\n",
    "    # 'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    # 'Date - Content sent for approval to network (K.S.)',\n",
    "    # 'Date Got Approval from Advertiser (K.S.)', 'Date Added to La Nina (Akshad)']\n",
    "    \n",
    "    # submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "    #                   'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "    #                   'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    #                   '# of Pieces Requested Per Shortcode', 'Shortcode', 'Requested By', 'RX Rep',\n",
    "    #                   'External AM Email', 'Channel', 'Platform']    \n",
    "    \n",
    "    df = df.merge(offers[['Hitpath Offer ID', 'Offer Name', 'Custom Creative Allowed', 'Vertical', 'Redirect Link', 'RX Rep', 'Advertiser Rep', 'Advertiser']], how='left', on='Hitpath Offer ID')\n",
    "    # Merge OW info\n",
    "    df = df.merge(ow[['Hitpath Offer ID', 'Vertical', 'Offer Wall Link']], how='left', on='Hitpath Offer ID', suffixes=['_normal', '_OW'])\n",
    "    df['Vertical'] = df.apply(lambda x: x['Vertical_normal'] if pd.isna(x['Vertical_OW']) else x['Vertical_OW'], axis=1)\n",
    "    df['Landing Page / Redirect Link'] = df.apply(lambda x: x['Redirect Link'] if pd.isna(x['Offer Wall Link']) else x['Offer Wall Link'], axis=1)\n",
    "    df = df.drop(['Vertical_normal', 'Vertical_OW', 'Offer Wall Link'], axis=1)\n",
    "    df = df.rename(columns={'Custom Creative Allowed':'Creative Approval Status', 'Num_Pieces_to_Request':'# of Pieces Requested Per Shortcode', 'Shortcode_Names':'Shortcode Abbreviations'})\n",
    "    \n",
    "    # df['Creative Approval Status'] = df['Creative Approval Status'].apply(lambda x: fix_approval_status(x))\n",
    "    df['Advertiser Rep'] = df['Advertiser Rep'].fillna('')\n",
    "    df['Shortcode Abbreviations'] = df['Shortcode Abbreviations'].apply(lambda x: '\\n'.join(x))\n",
    "    df['External AM Email'] = df.apply(lambda x: get_advertiser_email_address(x), axis=1)\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['Submission Date'] = pd.Timestamp(date.today())\n",
    "    df['Due Date '] = business_days_from_date(pd.Timestamp(date.today()), 3)\n",
    "    df['Request Type (Request)'] = 'Content'\n",
    "    df['Offer Type'] = 'Existing - More Content'\n",
    "    df['Compliance & Additional Notes (Request)'] = df['Hitpath Offer ID'].apply(lambda x: 'Offer Wall' if x in ow_hitpath_list else 'N/A')\n",
    "    df['Requested By'] = 'Script'\n",
    "    df['Channel'] = 'SC'\n",
    "    df['Platform'] = 'SS'\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['High Priority'] = False\n",
    "    # Need to make names match what is in Creative Submission sheet for contact email purposes\n",
    "    df['RX Rep'] = df['RX Rep'].apply(lambda x: find_closest_RX_Rep(x))\n",
    "\n",
    "    # # Ensure that index starts at 0 and increments by 1\n",
    "    # df = df.reset_index(drop=True)\n",
    "\n",
    "    # starting_id = get_starting_ID_number()\n",
    "    # df['Request ID'] = df.apply(lambda row: f'RQID.{starting_id+int(row.name)}.SMS', axis=1)\n",
    "    \n",
    "\n",
    "    df[['# of Pieces Requested Per Shortcode']] = df[['# of Pieces Requested Per Shortcode']].astype(int)\n",
    "    df['# of Pieces Requested Per Shortcode'] = df['# of Pieces Requested Per Shortcode'].apply(limit_requests_per_shortcode)\n",
    "\n",
    "\n",
    "    # For columns that do not yet exist, but are part of the SMS Creative Submission smartsheet, fill them with a blank string\n",
    "    missing_columns = [col for col in ct_columns if col not in df.columns]\n",
    "    for col in missing_columns:\n",
    "        df[col] = ''\n",
    "\n",
    "    df = df[ct_columns]\n",
    "\n",
    "    # Calculate number of shortcodes per hitpath\n",
    "    df['# of Shortcodes'] = df['Shortcode Abbreviations'].apply(lambda x: len(x.split('\\n')))\n",
    "    # Calculate total requests per hitpath \n",
    "    df['Total Requests per Hitpath'] = df['# of Pieces Requested Per Shortcode'] * df['# of Shortcodes']\n",
    "    \n",
    "    # Sort by highest amount of requests first, so that highest requests can be reduced, if necessary\n",
    "    df = df.sort_values(by='Total Requests per Hitpath', ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f5d11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_request_diff(df, request_limit):\n",
    "    \n",
    "    df['# of Shortcodes'] = df['Shortcode Abbreviations'].apply(lambda x: len(x.split('\\n')))\n",
    "    df['Total Requests per Hitpath'] = df['# of Pieces Requested Per Shortcode'] * df['# of Shortcodes']\n",
    "    total_requests = df['Total Requests per Hitpath'].sum()\n",
    "\n",
    "    request_diff = total_requests - request_limit\n",
    "\n",
    "    return request_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e30fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_out_dates(df):\n",
    "    total_requests = df['Total Requests per Hitpath'].sum()\n",
    "    first_third = total_requests * (1/3)\n",
    "    second_third = total_requests * (2/3)\n",
    "    original_due_date = df.iloc[0]['Due Date ']\n",
    "\n",
    "    df['Cumulative Request Total'] = df['Total Requests per Hitpath'].cumsum()\n",
    "\n",
    "    if len(df) > 1:\n",
    "        if len(df) == 2:\n",
    "            df.loc[1, 'Due Date '] = business_days_from_date(df.loc[0, 'Due Date '], 1)\n",
    "        else:\n",
    "            second_third_df = df[(df['Cumulative Request Total'] > first_third) & (df['Cumulative Request Total'] <= second_third)]\n",
    "            last_third_df = df[df['Cumulative Request Total'] > second_third]\n",
    "\n",
    "            for ind, row in second_third_df.iterrows():\n",
    "                df.loc[ind, 'Due Date '] = business_days_from_date(original_due_date, 1)\n",
    "            for ind, row in last_third_df.iterrows():\n",
    "                df.loc[ind, 'Due Date '] = business_days_from_date(original_due_date, 2)\n",
    "        \n",
    "    df = df.drop('Cumulative Request Total', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9dd77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_live_ow_inventory(row):\n",
    "    \"\"\"Takes a row from a dataframe and returns True if the Shortcode is a live Shortcode for the given OW\n",
    "    \n",
    "    :param row: a DataFrame row with columns of 'Hitpath Offer ID' and 'Shortcode Name'\n",
    "    :return: True or False\n",
    "    \"\"\"\n",
    "    if row['Hitpath Offer ID'] in live_ow_shortcodes_dict.keys():\n",
    "        key = row['Hitpath Offer ID']\n",
    "        value = row['Shortcode Name']\n",
    "        if value in live_ow_shortcodes_dict.get(key, []):\n",
    "            return True\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8664c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pieces_request_df(request_limit=50):\n",
    "    \"\"\"\n",
    "    Finds any Hitpath IDs that need more content and makes a dataframe of all content requests that need\n",
    "    to be made, formatted to be written into the SMS Creative Submission smartsheet\n",
    "    \n",
    "    :param request_limit: an int of the maximum number of total content pieces to be requested (sum of pieces requested * # of shortcodes).\n",
    "                         Default is 50.\n",
    "    :return a dataframe that is ready to be written into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "                    'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "                    'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "                    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Requested By', 'RX Rep',\n",
    "                    'External AM Email', 'Channel', 'Platform']  \n",
    "    # Find drops per month of each offer in each shortcode_DP.SV\n",
    "    dpm = lexi_90.copy()\n",
    "    dpm = dpm.drop_duplicates(subset=['shortcode_DP.SV', 'Date', 'Hitpath Offer ID'])\n",
    "    dpm = dpm.groupby(['shortcode_DP.SV', 'Hitpath Offer ID']).agg(drops_per_month=('Hitpath Offer ID', 'count'))\n",
    "    dpm['drops_per_month'] = dpm['drops_per_month'].apply(lambda x: int(np.ceil(x/3)))\n",
    "    dpm = dpm.reset_index()\n",
    "    dpm = dpm.merge(lexi_90[['shortcode_DP.SV', 'Shortcode Name']].drop_duplicates(subset='shortcode_DP.SV'), how='left', on='shortcode_DP.SV')\n",
    "    dpm = dpm.groupby(['Shortcode Name', 'Hitpath Offer ID'])[['drops_per_month']].max()\n",
    "    dpm = dpm.reset_index()\n",
    "\n",
    "    # Find how many content pieces there are currently for each offer\n",
    "    num_current_pieces = cw.groupby(['Type', 'OfferIDs']).agg(num_current_pieces=('Reporting Content ID', 'count'))\n",
    "    num_current_pieces = num_current_pieces.reset_index()\n",
    "    num_current_pieces = num_current_pieces.rename(columns={'Type':'Shortcode Name', 'OfferIDs':'Hitpath Offer ID'})\n",
    "\n",
    "    offer_inventory = dpm.merge(num_current_pieces, how='left', on=['Shortcode Name', 'Hitpath Offer ID'])\n",
    "    # Ensure that every hitpath that has dropped before has at least 2 pieces of content\n",
    "    offer_inventory['Required Num of Pieces'] = offer_inventory['drops_per_month'].apply(lambda x: max(x, 2))\n",
    "\n",
    "    stats_by_creative, bad_offers_dict = make_stats_by_creative()\n",
    "\n",
    "    # Include number of bad offers\n",
    "    offer_inventory['Poor Quality Pieces'] = offer_inventory.apply(lambda x: get_bad_offer_count(x, bad_offers_dict), axis=1)\n",
    "\n",
    "    offer_inventory['Num Pieces to Request'] = offer_inventory['Required Num of Pieces'] + offer_inventory['Poor Quality Pieces'] - offer_inventory['num_current_pieces']\n",
    "    offer_inventory['Num Pieces to Request'] = offer_inventory['Num Pieces to Request'].apply(lambda x: np.where(x < 0, 0, x))\n",
    "\n",
    "    offer_inventory = offer_inventory[offer_inventory['Shortcode Name'].isin(['DSS', 'FLC', 'HZB', 'MBC', 'SVT', 'UAA'])]\n",
    "\n",
    "    # Only keep shortcodes that are live for the offer wall\n",
    "    offer_inventory = offer_inventory[offer_inventory.apply(remove_not_live_ow_inventory, axis=1)]\n",
    "\n",
    "    # A list of Hitpath IDs that have had content requested recently\n",
    "    already_requested_content = find_already_requested_content()\n",
    "\n",
    "    # This will look at a given hitpath ID. If any shortcode has sent the offer in the past 90 days, it will be listed even if it has enough content\n",
    "    final_request_df = offer_inventory.groupby('Hitpath Offer ID').agg(Num_Pieces_to_Request=('Num Pieces to Request', 'max'), Shortcode_Names=('Shortcode Name', set))\n",
    "    # Only consider hitpath ids that need more content\n",
    "    final_request_df = final_request_df[final_request_df['Num_Pieces_to_Request'] > 0]\n",
    "    final_request_df = final_request_df[~final_request_df.index.isin(already_requested_content)]\n",
    "    final_request_df = final_request_df.reset_index()\n",
    "    \n",
    "    # Only consider offers that have sent as a P drop in the past 30 days\n",
    "    final_request_df = final_request_df[final_request_df['Hitpath Offer ID'].isin(eligible_hitpaths)]\n",
    "    \n",
    "    # Find offer status\n",
    "    final_request_df = final_request_df.merge(offers[['Hitpath Offer ID', 'Status']], how='left', on='Hitpath Offer ID')\n",
    "    # Give OW's a status \n",
    "    final_request_df['Status'] = final_request_df.apply(lambda x: ow_status_dict.get(x['Hitpath Offer ID'], x['Status']), axis=1)\n",
    "    # Only consider offers that are Live or Live: Budgeted Offers\n",
    "    final_request_df = final_request_df[final_request_df['Status'].isin(['Live', 'Live: Budgeted Offer'])]\n",
    "\n",
    "    # Ensure that OW's are requesting content only for Available Shortcodes\n",
    "    final_request_df['Shortcode_Names'] = final_request_df.apply(lambda x: live_ow_shortcodes_dict.get(x['Hitpath Offer ID'], x['Shortcode_Names']), axis=1)\n",
    "\n",
    "    # Get extra info necessary for submission sheet, and format properly\n",
    "    submission_df = finalize_submission_df(final_request_df)\n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    # Determine priority based on offer performance to choose which requests to remove first\n",
    "    stats_by_offer, priority_dict = make_stats_by_offer(submission_df['Hitpath Offer ID'])\n",
    "\n",
    "    stats_by_offer = stats_by_offer.merge(submission_df[['Hitpath Offer ID', '# of Pieces Requested Per Shortcode', 'Shortcode Abbreviations', '# of Shortcodes', 'Total Requests per Hitpath']], how='left', on='Hitpath Offer ID')\n",
    "    stats_by_offer = stats_by_offer.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[True, False])\n",
    "\n",
    "    # Do not want to request content that is performing poorly and thus not sending much--must have sent approx. 2 drops to each shortcode before requesting content \n",
    "    offer_30D_drop_count = lexi_30[lexi_30['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    offer_90D_drop_count = lexi_90[lexi_90['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    submission_df['30D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_30D_drop_count['Num_Drops'])\n",
    "    submission_df['90D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    # Must have sent enough drops that there could be 2 drops to each shortcode\n",
    "    submission_df = submission_df[submission_df['30D Drop Count'] >= (2 * submission_df['# of Shortcodes'])]\n",
    "\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer['Hitpath Offer ID'].isin(submission_df['Hitpath Offer ID'])]\n",
    "    stats_by_offer['90D Drop Count'] = stats_by_offer['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    stats_by_offer = stats_by_offer.rename(columns={'Num_Drops':'30D Drop Count'})\n",
    "    stats_by_offer['30:90 Ratio'] = stats_by_offer['30D Drop Count'] / stats_by_offer['90D Drop Count']\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer.columns[:5].tolist() + ['30D Drop Count', '90D Drop Count', '30:90 Ratio'] + stats_by_offer.columns[6:-2].tolist()]\n",
    "    # Restart ranking from 1 \n",
    "    stats_by_offer['Priority Order'] = stats_by_offer['Priority Order'].rank(ascending=True)\n",
    "\n",
    "    # Order offers from least important to most important based on performance\n",
    "    submission_df['Priority Order'] = submission_df['Hitpath Offer ID'].apply(lambda x: priority_dict[x])\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[False, True])\n",
    "\n",
    "    request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "\n",
    "\n",
    "    \"\"\" This method first removes 1 request from each row, then cycles back through until all rows are at 1 request per hitpath.\n",
    "        It then removes rows.\"\"\"\n",
    "    # while submission_df['# of Pieces Requested Per Shortcode'].max() > 1:\n",
    "    #     # Remove 1 hitpath request if there are at least 2 until request limit met\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         if row['# of Pieces Requested Per Shortcode'] > 1:\n",
    "    #             submission_df.loc[ind, '# of Pieces Requested Per Shortcode'] = row['# of Pieces Requested Per Shortcode'] - 1\n",
    "    #         else:\n",
    "    #             continue\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    #     if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # If request limit still is not met, remove low priority hitpath requests until request limit met\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "\n",
    "\n",
    "    # \"\"\" This method removes entire rows at a time (hitpath requests) until request limit is met\"\"\"\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # Place top priority offers first\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[True, False])\n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    total_requests = 0\n",
    "    final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "\n",
    "    for index, row in submission_df.iterrows():\n",
    "        if total_requests + row['Total Requests per Hitpath'] <= request_limit:\n",
    "            final_submission_df = pd.concat([final_submission_df, pd.DataFrame([row], columns=submission_df.columns)], ignore_index=True)\n",
    "            total_requests += row['Total Requests per Hitpath']\n",
    "\n",
    "    # \"\"\"This method adds request rows until it gets to (or close to) the request limit\"\"\"\n",
    "    # final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "    # for ind, row in submission_df.iterrows():\n",
    "    #     print(ind)\n",
    "    #     request_diff = calculate_request_diff(final_submission_df, request_limit)\n",
    "    #     print(request_diff)\n",
    "    #     if request_diff < 0:\n",
    "    #         final_submission_df = pd.concat([final_submission_df, row], ignore_index=True)\n",
    "    #     else:\n",
    "    #         continue\n",
    "\n",
    "    final_submission_df = spread_out_dates(final_submission_df)\n",
    "\n",
    "    # Get Dates into proper format for smartsheet submission (must be 'YYYY-MM-DD')\n",
    "    for col in ['Submission Date', 'Due Date ']:\n",
    "        final_submission_df[col] = final_submission_df[col].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # submission_df = submission_df.drop(['# of Shortcodes', 'Total Requests per Hitpath', 'Priority Order'], axis=1)\n",
    "\n",
    "    final_submission_df['# of Pieces Requested Per Toll Free'] = 0\n",
    "\n",
    "    # Only keep necessary columns\n",
    "    final_submission_df = final_submission_df[submission_columns]\n",
    "\n",
    "    # Cannot have NaNs when writing to smartsheet\n",
    "    final_submission_df = final_submission_df.fillna('')\n",
    "\n",
    "    offer_inventory = offer_inventory.rename(columns={'drops_per_month':'Max Drops Per Month', 'num_current_pieces':'Num Content Pieces in La Nina'})\n",
    "    offer_inventory = offer_inventory.fillna(0)\n",
    "    offer_inventory[offer_inventory.columns[2:]] = offer_inventory[offer_inventory.columns[2:]].astype(int)\n",
    "    offer_inventory = offer_inventory.sort_values(by=['Hitpath Offer ID', 'Shortcode Name'])\n",
    "\n",
    "    # Need to have Hitpath Offer ID column as an int so that Status can be pulled properly\n",
    "    final_submission_df['Hitpath Offer ID'] = final_submission_df['Hitpath Offer ID'].apply(lambda x: int(x) if x.isdigit() else x)\n",
    "\n",
    "    return final_submission_df, stats_by_offer, stats_by_creative, offer_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1363c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_number_to_letter(num_sheet_cols):\n",
    "    \"\"\"\n",
    "    Takes the 1-indexed number of a column in a google sheet and returns the letter version. For example,\n",
    "    if num_sheet_cols=1, it would return 'A'. If it was 27, it would return 'AA'. If it was 53, it would return 'BA'.\n",
    "\n",
    "    :param num_sheet_cols: an int of the column in the google sheet\n",
    "    :return: a string of the corresponding letter(s) of the column\n",
    "    \"\"\"\n",
    "    # One letter cases (A-Z)\n",
    "    if ((num_sheet_cols // 26) == 0) | (num_sheet_cols == 26):\n",
    "        letter = chr(64 + num_sheet_cols)\n",
    "\n",
    "    # Multiple letter cases (i.e. AA)\n",
    "    else:\n",
    "        # Z special case\n",
    "        if num_sheet_cols % 26 == 0:\n",
    "            first_letter = chr(64 + (num_sheet_cols // 26) - 1)\n",
    "            second_letter = chr(64 + num_sheet_cols - (((num_sheet_cols // 26) - 1) * 26))\n",
    "            letter = (first_letter + second_letter)\n",
    "        # All other letters\n",
    "        else:\n",
    "            first_letter = chr(64 + (num_sheet_cols // 26))\n",
    "            second_letter = chr(64 + num_sheet_cols - ((num_sheet_cols // 26) * 26))\n",
    "            letter = (first_letter + second_letter)\n",
    "\n",
    "    return letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bbbdef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_script_requests():\n",
    "    last_script_request_date = ct[ct['Requested By']=='Script']['Submission Date'].max()\n",
    "    prev_requests = ct[(ct['Requested By']=='Script') & (ct['Submission Date']==last_script_request_date)]\n",
    "\n",
    "    return prev_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bb01c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rx_rep_offer_counts(submission_df):\n",
    "    rep_dict = submission_df.groupby('RX Rep')['Hitpath Offer ID'].count().to_dict()\n",
    "    if '' in rep_dict.keys():\n",
    "        rep_dict['Offer Wall'] = rep_dict['']\n",
    "        del rep_dict['']\n",
    "    \n",
    "    # Sort alphabetically based on first name\n",
    "    rep_dict = dict(sorted(rep_dict.items()))\n",
    "    \n",
    "    return rep_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056dcd9",
   "metadata": {},
   "source": [
    "# Function for TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "780ebea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_already_requested_tf_content():\n",
    "    \"\"\"\n",
    "    :return: a list of Hitpath Offer IDs that have had TF content requested within the past 3 weeks in the \n",
    "            SMS Creative Submission smartsheet.\n",
    "    \"\"\"\n",
    "    already_requested_content = ct.copy()\n",
    "    already_requested_content = already_requested_content[['Submission Date', 'Date Added to La Nina (Akshad)', '# of Pieces Requested Per Toll Free', 'Hitpath Offer ID', 'Request Type (Request)','Toll Free Abbreviations']]\n",
    "    already_requested_content = already_requested_content[already_requested_content['Request Type (Request)'].str.contains('Content', na=False) ]\n",
    "    # Any offer without a date in this column has not been added to La Nina, and should not be requested again\n",
    "    already_requested_content = already_requested_content[((pd.isna(already_requested_content['Date Added to La Nina (Akshad)']))&(already_requested_content['Submission Date']>=pd.Timestamp(date.today()-timedelta(30)))) | \n",
    "                                                          (already_requested_content['Date Added to La Nina (Akshad)']>=pd.Timestamp(date.today() - timedelta(21)))]\n",
    "    already_requested_content = already_requested_content[ already_requested_content['# of Pieces Requested Per Toll Free']>0]                                                      \n",
    "\n",
    "    return already_requested_content['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d0aea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_submission_tf_df(df,request_tf):\n",
    "    \"\"\"\n",
    "    Properly formats the dataframe containing info on # of Pieces needed to be requested so that it can be pasted into\n",
    "    the SMS Creative Submission smartsheet. Also, gathers any additional information needed.\n",
    "\n",
    "    :param df: a dataframe of the # of pieces needed to be requested for each Shortcode/Hitpath ID combo\n",
    "    :return: a dataframe that is ready to be pasted into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    ct_columns = ['Hitpath ID', 'Request ID', 'High Priority', 'Submission Date',\n",
    "    'Due Date ', 'Request Sent to Copywriter (Kellie)', 'Unapproved Content Document Link (Copywriter)',\n",
    "    'Unapproved Jump Page Content (Copywriter)', 'Image ID - Jump Page (Copywriter)', 'Request Type (Request)',\n",
    "    'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    'Jump Page Link (Akshad)', 'Creative Approval Status', 'Date - Content sent for approval to network (K.S.)',\n",
    "    'Date Got Approval from Advertiser (K.S.)', 'Approved Jump Page Link (Kellie)', 'External - Approved Content Document (Kellie)',\n",
    "    'Ready for Akshad (Kellie Checks; Alert Sent)', 'Date Added to La Nina (Akshad)', 'Offer Type', 'Operational Status (Connected to SMS-OMA)',\n",
    "    'Hitpath Offer ID', 'Offer Name', 'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Toll Free Abbreviations', 'Requested By', \n",
    "    'RX Rep', 'External AM Email', 'Channel', 'Platform']\n",
    "\n",
    "    # date_columns = ['Submission Date', 'Due Date ', 'Request Sent to Copywriter (Kellie)',\n",
    "    # 'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    # 'Date - Content sent for approval to network (K.S.)',\n",
    "    # 'Date Got Approval from Advertiser (K.S.)', 'Date Added to La Nina (Akshad)']\n",
    "    \n",
    "    # submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "    #                   'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "    #                   'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    #                   '# of Pieces Requested Per Shortcode', 'Shortcode', 'Requested By', 'RX Rep',\n",
    "    #                   'External AM Email', 'Channel', 'Platform']    \n",
    "\n",
    "    df = df.merge(offers[['Hitpath Offer ID', 'Offer Name', 'Custom Creative Allowed', 'Vertical', 'Redirect Link', 'RX Rep', 'Advertiser Rep', 'Advertiser']], how='left', on='Hitpath Offer ID')\n",
    "    # Merge OW info\n",
    "    df['Landing Page / Redirect Link'] = df['Redirect Link']\n",
    "    df = df.rename(columns={'Custom Creative Allowed':'Creative Approval Status', 'Pieces to Request':'# of Pieces Requested Per Toll Free'})\n",
    "    \n",
    "    # df['Creative Approval Status'] = df['Creative Approval Status'].apply(lambda x: fix_approval_status(x))\n",
    "    df['Advertiser Rep'] = df['Advertiser Rep'].fillna('')\n",
    "    df['Toll Free Abbreviations'] = '\\n'.join(request_tf)\n",
    "    df['External AM Email'] = df.apply(lambda x: get_advertiser_email_address(x), axis=1)\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['Submission Date'] = pd.Timestamp(date.today())\n",
    "    df['Due Date '] = business_days_from_date(pd.Timestamp(date.today()), 3)\n",
    "    df['Request Type (Request)'] = 'Content'\n",
    "    df['Offer Type'] = 'Existing - More Content'\n",
    "    df['Compliance & Additional Notes (Request)'] = 'Extra Content for direct traffic in Toll Free'\n",
    "    df['Requested By'] = 'Script'\n",
    "    df['Channel'] = 'TF'\n",
    "    df['Platform'] = 'SS'\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['High Priority'] = False\n",
    "    # Need to make names match what is in Creative Submission sheet for contact email purposes\n",
    "    df['RX Rep'] = df['RX Rep'].apply(lambda x: find_closest_RX_Rep(x))\n",
    "\n",
    "    # # Ensure that index starts at 0 and increments by 1\n",
    "    # df = df.reset_index(drop=True)\n",
    "\n",
    "    # starting_id = get_starting_ID_number()\n",
    "    # df['Request ID'] = df.apply(lambda row: f'RQID.{starting_id+int(row.name)}.SMS', axis=1)\n",
    "    \n",
    "\n",
    "    df[['# of Pieces Requested Per Toll Free']] = df[['# of Pieces Requested Per Toll Free']].astype(int)\n",
    "\n",
    "    # For columns that do not yet exist, but are part of the SMS Creative Submission smartsheet, fill them with a blank string\n",
    "    missing_columns = [col for col in ct_columns if col not in df.columns]\n",
    "    for col in missing_columns:\n",
    "        df[col] = ''\n",
    "\n",
    "    df = df[ct_columns]\n",
    "\n",
    "    # Calculate number of shortcodes per hitpath\n",
    "    df['# of Shortcodes'] = df['Toll Free Abbreviations'].apply(lambda x: len(x.split('\\n')))\n",
    "    # Calculate total requests per hitpath \n",
    "    df['Total Requests per Hitpath'] = df['# of Pieces Requested Per Toll Free'] * df['# of Shortcodes']\n",
    "    \n",
    "    # Sort by highest amount of requests first, so that highest requests can be reduced, if necessary\n",
    "    df = df.sort_values(by='Total Requests per Hitpath', ascending=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3947b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_request_tf_diff(df, request_limit):\n",
    "    \n",
    "    df['# of Shortcodes'] = df['Toll Free Abbreviations'].apply(lambda x: len(x.split('\\n')))\n",
    "    df['Total Requests per Hitpath'] = df['# of Pieces Requested Per Toll Free'] * df['# of Shortcodes']\n",
    "    total_requests = df['Total Requests per Hitpath'].sum()\n",
    "\n",
    "    request_diff = total_requests - request_limit\n",
    "\n",
    "    return request_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54d2d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pieces_request_tf_df(submission_df,request_tf, request_limit=50):\n",
    "\n",
    "###########################\n",
    "    \"\"\"\n",
    "    Finds any Hitpath IDs that need more content and makes a dataframe of all content requests that need\n",
    "    to be made, formatted to be written into the SMS Creative Submission smartsheet\n",
    "    \n",
    "    :param request_limit: an int of the maximum number of total content pieces to be requested (sum of pieces requested * # of shortcodes).\n",
    "                         Default is 50.\n",
    "    :return a dataframe that is ready to be written into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "                    'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "                    'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "                    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Toll Free Abbreviations','Requested By', 'RX Rep',\n",
    "                    'External AM Email', 'Channel', 'Platform']   \n",
    "\n",
    "    # Get extra info necessary for submission sheet, and format properly\n",
    "    \n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    # Determine priority based on offer performance to choose which requests to remove first\n",
    "    stats_by_offer, priority_dict = make_stats_by_offer(submission_df['Hitpath Offer ID'])\n",
    "\n",
    "    stats_by_offer = stats_by_offer.merge(submission_df[['Hitpath Offer ID', '# of Pieces Requested Per Toll Free', 'Toll Free Abbreviations', '# of Shortcodes', 'Total Requests per Hitpath']], how='left', on='Hitpath Offer ID')\n",
    "    stats_by_offer = stats_by_offer.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[True, False])\n",
    "\n",
    "    # Do not want to request content that is performing poorly and thus not sending much--must have sent approx. 2 drops to each shortcode before requesting content \n",
    "    offer_30D_drop_count = lexi_30[lexi_30['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    offer_90D_drop_count = lexi_90[lexi_90['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    submission_df['30D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_30D_drop_count['Num_Drops'])\n",
    "    submission_df['90D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    # Must have sent enough drops that there could be 2 drops to each shortcode\n",
    "    submission_df = submission_df[submission_df['30D Drop Count'] >= (2 * submission_df['# of Shortcodes'])]\n",
    "\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer['Hitpath Offer ID'].isin(submission_df['Hitpath Offer ID'])]\n",
    "    stats_by_offer['90D Drop Count'] = stats_by_offer['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    stats_by_offer = stats_by_offer.rename(columns={'Num_Drops':'30D Drop Count'})\n",
    "    stats_by_offer['30:90 Ratio'] = stats_by_offer['30D Drop Count'] / stats_by_offer['90D Drop Count']\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer.columns[:5].tolist() + ['30D Drop Count', '90D Drop Count', '30:90 Ratio'] + stats_by_offer.columns[6:-2].tolist()]\n",
    "    # Restart ranking from 1 \n",
    "    stats_by_offer['Priority Order'] = stats_by_offer['Priority Order'].rank(ascending=True)\n",
    "\n",
    "    # Order offers from least important to most important based on performance\n",
    "    submission_df['Priority Order'] = submission_df['Hitpath Offer ID'].apply(lambda x: priority_dict[x])\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[False, True])\n",
    "\n",
    "    request_diff = calculate_request_tf_diff(submission_df, request_limit)\n",
    "\n",
    "\n",
    "    \"\"\" This method first removes 1 request from each row, then cycles back through until all rows are at 1 request per hitpath.\n",
    "        It then removes rows.\"\"\"\n",
    "    # while submission_df['# of Pieces Requested Per Shortcode'].max() > 1:\n",
    "    #     # Remove 1 hitpath request if there are at least 2 until request limit met\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         if row['# of Pieces Requested Per Shortcode'] > 1:\n",
    "    #             submission_df.loc[ind, '# of Pieces Requested Per Shortcode'] = row['# of Pieces Requested Per Shortcode'] - 1\n",
    "    #         else:\n",
    "    #             continue\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    #     if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # If request limit still is not met, remove low priority hitpath requests until request limit met\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "\n",
    "\n",
    "    # \"\"\" This method removes entire rows at a time (hitpath requests) until request limit is met\"\"\"\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # Place top priority offers first\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order', '# of Shortcodes'], ascending=[True, False])\n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    total_requests = 0\n",
    "    \n",
    "    final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "\n",
    "    for index, row in submission_df.iterrows():\n",
    "        if total_requests + row['Total Requests per Hitpath'] <= request_limit:\n",
    "            final_submission_df = pd.concat([final_submission_df, pd.DataFrame([row], columns=submission_df.columns)], ignore_index=True)\n",
    "            total_requests += row['Total Requests per Hitpath']\n",
    "    print(final_submission_df)\n",
    "    # \"\"\"This method adds request rows until it gets to (or close to) the request limit\"\"\"\n",
    "    # final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "    # for ind, row in submission_df.iterrows():\n",
    "    #     print(ind)\n",
    "    #     request_diff = calculate_request_diff(final_submission_df, request_limit)\n",
    "    #     print(request_diff)\n",
    "    #     if request_diff < 0:\n",
    "    #         final_submission_df = pd.concat([final_submission_df, row], ignore_index=True)\n",
    "    #     else:\n",
    "    #         continue\n",
    "\n",
    "    final_submission_df = spread_out_dates(final_submission_df)\n",
    "\n",
    "    # Get Dates into proper format for smartsheet submission (must be 'YYYY-MM-DD')\n",
    "    for col in ['Submission Date', 'Due Date ']:\n",
    "        final_submission_df[col] = final_submission_df[col].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # submission_df = submission_df.drop(['# of Shortcodes', 'Total Requests per Hitpath', 'Priority Order'], axis=1)\n",
    "\n",
    "    final_submission_df['# of Pieces Requested Per Shortcode'] = 0\n",
    "\n",
    "    # Only keep necessary columns\n",
    "    final_submission_df = final_submission_df[submission_columns]\n",
    "\n",
    "    # Cannot have NaNs when writing to smartsheet\n",
    "    final_submission_df = final_submission_df.fillna('')\n",
    "\n",
    "\n",
    "    # Need to have Hitpath Offer ID column as an int so that Status can be pulled properly\n",
    "    final_submission_df['Hitpath Offer ID'] = final_submission_df['Hitpath Offer ID'].apply(lambda x: int(x) if x.isdigit() else x)\n",
    "\n",
    "    return final_submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcb284",
   "metadata": {},
   "source": [
    "# Function for Full combined request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a701ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03202931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_submission_all_df(df):\n",
    "    \"\"\"\n",
    "    Properly formats the dataframe containing info on # of Pieces needed to be requested so that it can be pasted into\n",
    "    the SMS Creative Submission smartsheet. Also, gathers any additional information needed.\n",
    "\n",
    "    :param df: a dataframe of the # of pieces needed to be requested for each Shortcode/Hitpath ID combo\n",
    "    :return: a dataframe that is ready to be pasted into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    ct_columns = ['Hitpath ID', 'Request ID', 'High Priority', 'Submission Date',\n",
    "    'Due Date ', 'Request Sent to Copywriter (Kellie)', 'Unapproved Content Document Link (Copywriter)',\n",
    "    'Unapproved Jump Page Content (Copywriter)', 'Image ID - Jump Page (Copywriter)', 'Request Type (Request)',\n",
    "    'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    'Jump Page Link (Akshad)', 'Creative Approval Status', 'Date - Content sent for approval to network (K.S.)',\n",
    "    'Date Got Approval from Advertiser (K.S.)', 'Approved Jump Page Link (Kellie)', 'External - Approved Content Document (Kellie)','Seasonal Date Restriction',\n",
    "    'Ready for Akshad (Kellie Checks; Alert Sent)', 'Date Added to La Nina (Akshad)', 'Offer Type', 'Operational Status (Connected to SMS-OMA)',\n",
    "    'Hitpath Offer ID', 'Offer Name', 'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Toll Free Abbreviations', 'Requested By', \n",
    "    'RX Rep', 'External AM Email', 'Channel', 'Platform','Total Requests per Hitpath','Total Requests per Toll Free','# of Pieces Requested Per Jump Page']\n",
    "\n",
    "    # date_columns = ['Submission Date', 'Due Date ', 'Request Sent to Copywriter (Kellie)',\n",
    "    # 'Content Sent to Compliance (Kellie)', 'Content Approved by Compliance (Kellie)', 'Date - Jump Page Created (Akshad)',\n",
    "    # 'Date - Content sent for approval to network (K.S.)',\n",
    "    # 'Date Got Approval from Advertiser (K.S.)', 'Date Added to La Nina (Akshad)']\n",
    "    \n",
    "    # submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "    #                   'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "    #                   'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "    #                   '# of Pieces Requested Per Shortcode', 'Shortcode', 'Requested By', 'RX Rep',\n",
    "    #                   'External AM Email', 'Channel', 'Platform']    \n",
    "\n",
    "    df = df.merge(offers[['Hitpath Offer ID', 'Offer Name', 'Custom Creative Allowed', 'Vertical', 'Redirect Link', 'RX Rep', 'Advertiser Rep', 'Advertiser']], how='left', on='Hitpath Offer ID')\n",
    "    # Merge OW info\n",
    "    df['Landing Page / Redirect Link'] = df['Redirect Link']\n",
    "    df = df.rename(columns={'Custom Creative Allowed':'Creative Approval Status'})\n",
    "    \n",
    "    # df['Creative Approval Status'] = df['Creative Approval Status'].apply(lambda x: fix_approval_status(x))\n",
    "    df['Advertiser Rep'] = df['Advertiser Rep'].fillna('')\n",
    "    df['External AM Email'] = df.apply(lambda x: get_advertiser_email_address(x), axis=1)\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['Submission Date'] = pd.Timestamp(date.today())\n",
    "    df['Due Date '] = business_days_from_date(pd.Timestamp(date.today()), 3)\n",
    "    df['Request Type (Request)'] = df.apply(\n",
    "                lambda x: \"Content\" if x['# of Pieces Requested Per Jump Page'] == 0 \n",
    "                else \"Jump Page\" if x['# of Pieces Requested Per Toll Free'] + x['# of Pieces Requested Per Shortcode'] == 0 \n",
    "                else \"Content & Jump Page\", \n",
    "                axis=1\n",
    "                )\n",
    "    df['Offer Type'] = 'Existing - More Content'\n",
    "    df['Compliance & Additional Notes (Request)'] = ''\n",
    "    df['Requested By'] = 'Script'\n",
    "    df['Channel List'] = df.apply( lambda x: ['SC','TF'] if x['# of Pieces Requested Per Toll Free'] > 0 and x['# of Pieces Requested Per Shortcode']+ x['# of Pieces Requested Per Jump Page'] > 0 \n",
    "                                  else ['SC'] if  x['# of Pieces Requested Per Toll Free'] == 0\n",
    "                                  else ['TF'], axis= 1)\n",
    "    df['Channel'] = df['Channel List'].apply(lambda x: '\\n'.join(x))\n",
    "    df['Platform'] = 'SS'\n",
    "    df['Hitpath ID'] = df['Hitpath Offer ID']\n",
    "    df['High Priority'] = False\n",
    "    # Need to make names match what is in Creative Submission sheet for contact email purposes\n",
    "    df['RX Rep'] = df['RX Rep'].apply(lambda x: find_closest_RX_Rep(x))\n",
    "\n",
    "    # # Ensure that index starts at 0 and increments by 1\n",
    "    # df = df.reset_index(drop=True)\n",
    "\n",
    "    # starting_id = get_starting_ID_number()\n",
    "    # df['Request ID'] = df.apply(lambda row: f'RQID.{starting_id+int(row.name)}.SMS', axis=1)\n",
    "    \n",
    "\n",
    "    df[['# of Pieces Requested Per Toll Free']] = df[['# of Pieces Requested Per Toll Free']].astype(int)\n",
    "    df[['# of Pieces Requested Per Shortcode']] = df[['# of Pieces Requested Per Shortcode']].astype(int)\n",
    "    df['# of Pieces Requested Per Shortcode'] = df['# of Pieces Requested Per Shortcode'].apply(limit_requests_per_shortcode)\n",
    "\n",
    "    # For columns that do not yet exist, but are part of the SMS Creative Submission smartsheet, fill them with a blank string\n",
    "    missing_columns = [col for col in ct_columns if col not in df.columns]\n",
    "    for col in missing_columns:\n",
    "        df[col] = ''\n",
    "\n",
    "    df = df[ct_columns]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299fa9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pieces_request_all_df(submission_df,request_limit = 50 ):     \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Finds any Hitpath IDs that need more content and makes a dataframe of all content requests that need\n",
    "    to be made, formatted to be written into the SMS Creative Submission smartsheet\n",
    "    \n",
    "    :param request_limit: an int of the maximum number of total content pieces to be requested (sum of pieces requested * # of shortcodes).\n",
    "                         Default is 50.\n",
    "    :return a dataframe that is ready to be written into the SMS Creative Submission smartsheet\n",
    "    \"\"\"\n",
    "    submission_columns = ['Hitpath ID', 'Submission Date', 'Due Date ', 'Request Type (Request)',\n",
    "                    'Creative Approval Status', 'Offer Type', 'Hitpath Offer ID', 'Offer Name',\n",
    "                    'Vertical', 'Landing Page / Redirect Link', 'Compliance & Additional Notes (Request)',\n",
    "                    '# of Pieces Requested Per Shortcode', '# of Pieces Requested Per Toll Free', 'Shortcode Abbreviations', 'Toll Free Abbreviations','Requested By', 'RX Rep',\n",
    "                    'External AM Email', 'Channel', 'Platform']   \n",
    "\n",
    "    # Get extra info necessary for submission sheet, and format properly\n",
    "    \n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    # Determine priority based on offer performance to choose which requests to remove first\n",
    "    stats_by_offer, priority_dict = make_stats_by_offer(submission_df['Hitpath Offer ID'])\n",
    "\n",
    "    stats_by_offer = stats_by_offer.merge(submission_df[['Hitpath Offer ID', '# of Pieces Requested Per Toll Free', 'Toll Free Abbreviations', 'Shortcode Abbreviations', '# of Pieces Requested Per Shortcode','# of Pieces Requested Per Jump Page']], how='left', on='Hitpath Offer ID')\n",
    "    stats_by_offer = stats_by_offer.sort_values(by=['Priority Order'], ascending=[True])\n",
    "\n",
    "    # Do not want to request content that is performing poorly and thus not sending much--must have sent approx. 2 drops to each shortcode before requesting content \n",
    "    offer_30D_drop_count = lexi_30[lexi_30['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    offer_90D_drop_count = lexi_90[lexi_90['Hitpath Offer ID'].isin(stats_by_offer['Hitpath Offer ID'])].groupby(['Hitpath Offer ID']).agg(Num_Drops=('Date', 'count')).to_dict()\n",
    "    submission_df['30D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_30D_drop_count['Num_Drops'])\n",
    "    submission_df['90D Drop Count'] = submission_df['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    # Must have sent enough drops that there could be 2 drops to each shortcode\n",
    "    submission_df = submission_df[submission_df['30D Drop Count'] >= 10]\n",
    "\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer['Hitpath Offer ID'].isin(submission_df['Hitpath Offer ID'])]\n",
    "    stats_by_offer['90D Drop Count'] = stats_by_offer['Hitpath Offer ID'].map(offer_90D_drop_count['Num_Drops'])\n",
    "    stats_by_offer = stats_by_offer.rename(columns={'Num_Drops':'30D Drop Count'})\n",
    "    stats_by_offer['30:90 Ratio'] = stats_by_offer['30D Drop Count'] / stats_by_offer['90D Drop Count']\n",
    "    stats_by_offer = stats_by_offer[stats_by_offer.columns[:5].tolist() + ['30D Drop Count', '90D Drop Count', '30:90 Ratio'] + stats_by_offer.columns[6:-2].tolist()]\n",
    "    # Restart ranking from 1 \n",
    "    stats_by_offer['Priority Order'] = stats_by_offer['Priority Order'].rank(ascending=True)\n",
    "\n",
    "    # Order offers from least important to most important based on performance\n",
    "    submission_df['Priority Order'] = submission_df['Hitpath Offer ID'].apply(lambda x: priority_dict[x])\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order'], ascending=[False])\n",
    "    \n",
    "    \n",
    "    submission_df['Total Requests per Toll Free'] = submission_df['Total Requests per Toll Free'].fillna(0)\n",
    "    submission_df['Total Requests per Hitpath'] = submission_df['Total Requests per Hitpath'].fillna(0)\n",
    "    submission_df['Total Request'] = submission_df['Total Requests per Toll Free'] + submission_df['Total Requests per Hitpath']\n",
    "    submission_df.loc[submission_df['Total Requests per Hitpath']!=0, 'Total Request'] = submission_df['Total Requests per Hitpath']\n",
    "    submission_df.loc[submission_df['Total Request']==0, 'Total Request'] = 1\n",
    "    total_requests = submission_df['Total Requests per Toll Free'].sum()+ submission_df['Total Requests per Hitpath'].sum()\n",
    "    request_diff = total_requests - request_limit\n",
    "\n",
    "    \"\"\" This method first removes 1 request from each row, then cycles back through until all rows are at 1 request per hitpath.\n",
    "        It then removes rows.\"\"\"\n",
    "    # while submission_df['# of Pieces Requested Per Shortcode'].max() > 1:\n",
    "    #     # Remove 1 hitpath request if there are at least 2 until request limit met\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         if row['# of Pieces Requested Per Shortcode'] > 1:\n",
    "    #             submission_df.loc[ind, '# of Pieces Requested Per Shortcode'] = row['# of Pieces Requested Per Shortcode'] - 1\n",
    "    #         else:\n",
    "    #             continue\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    #     if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # If request limit still is not met, remove low priority hitpath requests until request limit met\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "\n",
    "\n",
    "    # \"\"\" This method removes entire rows at a time (hitpath requests) until request limit is met\"\"\"\n",
    "    # if request_diff > 0:\n",
    "    #     for ind, row in submission_df.iterrows():\n",
    "    #         submission_df = submission_df.drop(ind)\n",
    "    #         request_diff = calculate_request_diff(submission_df, request_limit)\n",
    "    #         if request_diff <= 0:\n",
    "    #             break\n",
    "    \n",
    "    # # Place top priority offers first\n",
    "    submission_df = submission_df.sort_values(by=['Priority Order'], ascending=[True])\n",
    "    submission_df = submission_df.reset_index(drop=True)\n",
    "\n",
    "    total_requests = 0\n",
    "    \n",
    "    final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "\n",
    "    for index, row in submission_df.iterrows():\n",
    "        if total_requests + row['Total Request'] <= request_limit:\n",
    "            final_submission_df = pd.concat([final_submission_df, pd.DataFrame([row], columns=submission_df.columns)], ignore_index=True)\n",
    "            total_requests += row['Total Request']\n",
    "    print(final_submission_df)\n",
    "    # \"\"\"This method adds request rows until it gets to (or close to) the request limit\"\"\"\n",
    "    # final_submission_df = pd.DataFrame(columns=submission_df.columns)\n",
    "    # for ind, row in submission_df.iterrows():\n",
    "    #     print(ind)\n",
    "    #     request_diff = calculate_request_diff(final_submission_df, request_limit)\n",
    "    #     print(request_diff)\n",
    "    #     if request_diff < 0:\n",
    "    #         final_submission_df = pd.concat([final_submission_df, row], ignore_index=True)\n",
    "    #     else:\n",
    "    #         continue\n",
    "\n",
    "    final_submission_df = spread_out_dates(final_submission_df)\n",
    "\n",
    "    # Get Dates into proper format for smartsheet submission (must be 'YYYY-MM-DD')\n",
    "    for col in ['Submission Date', 'Due Date ']:\n",
    "        final_submission_df[col] = final_submission_df[col].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # submission_df = submission_df.drop(['# of Shortcodes', 'Total Requests per Hitpath', 'Priority Order'], axis=1)\n",
    "\n",
    "\n",
    "    # Only keep necessary columns\n",
    "    final_submission_df = final_submission_df[submission_columns]\n",
    "\n",
    "    # Cannot have NaNs when writing to smartsheet\n",
    "    final_submission_df = final_submission_df.fillna('')\n",
    "\n",
    "\n",
    "    # Need to have Hitpath Offer ID column as an int so that Status can be pulled properly\n",
    "    final_submission_df['Hitpath Offer ID'] = final_submission_df['Hitpath Offer ID'].apply(lambda x: int(x) if x.isdigit() else x)\n",
    "\n",
    "    return final_submission_df, stats_by_offer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d38255",
   "metadata": {},
   "source": [
    "# Make DataFrame, Save as Excel, and Write to Smartsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "474ca20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hitpath ID</th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Due Date</th>\n",
       "      <th>Request Type (Request)</th>\n",
       "      <th>Creative Approval Status</th>\n",
       "      <th>Offer Type</th>\n",
       "      <th>Hitpath Offer ID</th>\n",
       "      <th>Offer Name</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Landing Page / Redirect Link</th>\n",
       "      <th>Compliance &amp; Additional Notes (Request)</th>\n",
       "      <th># of Pieces Requested Per Shortcode</th>\n",
       "      <th># of Pieces Requested Per Toll Free</th>\n",
       "      <th>Shortcode Abbreviations</th>\n",
       "      <th>Requested By</th>\n",
       "      <th>RX Rep</th>\n",
       "      <th>External AM Email</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13059</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>13059</td>\n",
       "      <td>EXCLUSIVE - 2024FreeScores</td>\n",
       "      <td>Credit Score</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=13059&amp;p...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>FLC\\nHZB\\nDSS\\nMBC\\nSVT\\nUAA</td>\n",
       "      <td>Script</td>\n",
       "      <td>Mary Beth Howe</td>\n",
       "      <td>Kara Moore kara@cx3ads.com</td>\n",
       "      <td>SC</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13089</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>13089</td>\n",
       "      <td>HomeSafeGuarded Home Insurance - B2D</td>\n",
       "      <td>Home Insurance</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=13089&amp;p...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>DSS\\nMBC\\nFLC\\nHZB</td>\n",
       "      <td>Script</td>\n",
       "      <td>Hartley Goode</td>\n",
       "      <td>Madison Housel - madison@btwodirect.com</td>\n",
       "      <td>SC</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hitpath ID Submission Date   Due Date  Request Type (Request)  \\\n",
       "0      13059      2024-07-16  2024-07-19                Content   \n",
       "1      13089      2024-07-16  2024-07-22                Content   \n",
       "\n",
       "         Creative Approval Status               Offer Type  Hitpath Offer ID  \\\n",
       "0  Yes - need advertiser approval  Existing - More Content             13059   \n",
       "1  Yes - need advertiser approval  Existing - More Content             13089   \n",
       "\n",
       "                             Offer Name        Vertical  \\\n",
       "0            EXCLUSIVE - 2024FreeScores    Credit Score   \n",
       "1  HomeSafeGuarded Home Insurance - B2D  Home Insurance   \n",
       "\n",
       "                        Landing Page / Redirect Link  \\\n",
       "0  https://www.rentonion.com/rd/r.php?sid=13059&p...   \n",
       "1  https://www.rentonion.com/rd/r.php?sid=13089&p...   \n",
       "\n",
       "  Compliance & Additional Notes (Request)  \\\n",
       "0                                     N/A   \n",
       "1                                     N/A   \n",
       "\n",
       "   # of Pieces Requested Per Shortcode  # of Pieces Requested Per Toll Free  \\\n",
       "0                                    2                                    0   \n",
       "1                                    2                                    0   \n",
       "\n",
       "        Shortcode Abbreviations Requested By          RX Rep  \\\n",
       "0  FLC\\nHZB\\nDSS\\nMBC\\nSVT\\nUAA       Script  Mary Beth Howe   \n",
       "1            DSS\\nMBC\\nFLC\\nHZB       Script   Hartley Goode   \n",
       "\n",
       "                         External AM Email Channel Platform  \n",
       "0               Kara Moore kara@cx3ads.com      SC       SS  \n",
       "1  Madison Housel - madison@btwodirect.com      SC       SS  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df, stats_by_offer, stats_by_creative, offer_inventory = make_pieces_request_df(request_limit=20)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91388ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_requests = get_previous_script_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "357463d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_rep_offer_dict = get_rx_rep_offer_counts(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ac3ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import flatten\n",
    "from openpyxl.styles import numbers\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Color, colors, fills\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from openpyxl.styles.borders import Border, Side, BORDER_THIN\n",
    "thin_border = Border(\n",
    "    left=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    right=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    top=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    bottom=Side(border_style=BORDER_THIN, color='D3D3D3')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b34ff1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make Recently Tested Content Report\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "all_sheets = []\n",
    "ws_headers = {}\n",
    "\n",
    "ws_headers['Content Requests'] = submission_df.columns.tolist()\n",
    "ws_headers['Stats by Offer'] = stats_by_offer.columns.tolist()\n",
    "ws_headers['Stats by Creative'] = stats_by_creative.columns.tolist()\n",
    "ws_headers['Offer Inventory'] = offer_inventory.columns.tolist()\n",
    "ws_headers['Previous Script Requests'] = prev_requests.columns.tolist()\n",
    "\n",
    "submission_df_hitpaths = submission_df['Hitpath Offer ID'].tolist()\n",
    "submission_df_hitpaths = [str(x) for x in submission_df_hitpaths]\n",
    "\n",
    "stats_by_offer_hitpaths = stats_by_offer['Hitpath Offer ID'].tolist()\n",
    "stats_by_offer_hitpaths = [str(x) for x in stats_by_offer_hitpaths]\n",
    "\n",
    "\n",
    "hitpath_requests_removed = [hitpath for hitpath in stats_by_offer_hitpaths if hitpath not in submission_df_hitpaths]\n",
    "\n",
    "\n",
    "content_request_sheet = wb['Sheet']\n",
    "content_request_sheet.title = 'Content Requests'\n",
    "\n",
    "# Column names to format specially\n",
    "currency_format_cols = ['Revenue', 'eCPM', 'eCPM_min_target']\n",
    "percent_format_cols = ['OOR', 'CTR', 'CTR_min_target', '30:90 Ratio']\n",
    "comma_format_cols = ['Optout', 'Clicks', 'Delivered']\n",
    "\n",
    "for r in dataframe_to_rows(submission_df, index=False, header=True):\n",
    "    content_request_sheet.append(r)\n",
    "all_sheets.append(content_request_sheet)\n",
    "\n",
    "stats_by_offer_sheet = wb.create_sheet('Stats by Offer')\n",
    "for r in dataframe_to_rows(stats_by_offer, index=False, header=True):\n",
    "    stats_by_offer_sheet.append(r)\n",
    "all_sheets.append(stats_by_offer_sheet)\n",
    "\n",
    "stats_by_creative_sheet = wb.create_sheet('Stats by Creative')\n",
    "for r in dataframe_to_rows(stats_by_creative, index=False, header=True):\n",
    "    stats_by_creative_sheet.append(r)\n",
    "all_sheets.append(stats_by_creative_sheet)\n",
    "\n",
    "offer_inventory_sheet = wb.create_sheet('Offer Inventory')\n",
    "for r in dataframe_to_rows(offer_inventory, index=False, header=True):\n",
    "    offer_inventory_sheet.append(r)\n",
    "all_sheets.append(offer_inventory_sheet)\n",
    "\n",
    "prev_requests_sheet = wb.create_sheet('Previous Script Requests')\n",
    "for r in dataframe_to_rows(prev_requests, index=False, header=True):\n",
    "    prev_requests_sheet.append(r)\n",
    "all_sheets.append(prev_requests_sheet)\n",
    "\n",
    "logic_and_definitions_sheet = wb.create_sheet('Logic and Definitions')\n",
    "logic_and_definitions_sheet.cell(1, 1).value = 'Logic:'\n",
    "logic_and_definitions_sheet.cell(1, 2).value = 'https://docs.google.com/document/d/1mYEPQHOprX170u_882O5fiQqLCohWGwmnE34o7iuwuQ/edit?usp=sharing'\n",
    "logic_and_definitions_sheet.cell(2, 1).value = 'Definitions:'\n",
    "logic_and_definitions_sheet.cell(2, 2).value = 'https://docs.google.com/document/d/1Og0j8Bwzl8kim9_LCgQ6MLrt2_BkWEiwguCNWsKwQgg/edit?usp=sharing'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ws in all_sheets:\n",
    "    dims = {}\n",
    "    headers = ws_headers[ws.title]\n",
    "\n",
    "    for row in ws.rows:\n",
    "        for cell in ws[\"1:1\"]:\n",
    "            cell.font = Font(bold=True)\n",
    "        for cell in row:\n",
    "            newline_count = 1\n",
    "            if cell.value:\n",
    "                if type(cell.value)==str:\n",
    "                    if ('\\n' in cell.value):\n",
    "                        newline_count = cell.value.count('\\n')\n",
    "                dims[cell.column_letter] = max((dims.get(cell.column_letter, 0), len(str(cell.value))))/newline_count \n",
    "    for col, value in dims.items():\n",
    "        ws.column_dimensions[col].width = value\n",
    "\n",
    "    for col in currency_format_cols:\n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_CURRENCY_USD_SIMPLE\n",
    "\n",
    "    for col in percent_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_PERCENTAGE_00\n",
    "\n",
    "    for col in comma_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = '#,##0'\n",
    "\n",
    "    ws.freeze_panes = 'A2'\n",
    "\n",
    "# Make entire row orange if offer was removed from requests\n",
    "for row in stats_by_offer_sheet.iter_rows(min_row=2):\n",
    "    # If the Sendable column if False, make entire row orange\n",
    "    if row[ws_headers['Stats by Offer'].index('Hitpath Offer ID')].value in hitpath_requests_removed:\n",
    "        for cell in row:     \n",
    "            cell.fill = fills.PatternFill(patternType='solid', fgColor=Color(rgb='fce5cd'))\n",
    "            cell.border = thin_border\n",
    "\n",
    "# # Make OOR orange if more than 2%\n",
    "# for row in stats_by_creative_sheet.iter_rows(min_row=2, min_col=ws_headers['Stats by Creative'].index('OOR') + 1, max_col=ws_headers['Stats by Creative'].index('OOR') + 1):\n",
    "#     value = row[0].value\n",
    "#     if value is not None and value >= 0.02:\n",
    "#         stats_by_creative_sheet.cell(row=row[0].row, column=ws_headers['Stats by Creative'].index('OOR') + 1).fill = fills.PatternFill(patternType='solid', fgColor=Color(rgb='fce5cd'))\n",
    "\n",
    "# Pair CTR and eCPM columns with target columns\n",
    "ctr_comparison = (ws_headers['Stats by Creative'].index('CTR') + 1, ws_headers['Stats by Creative'].index('CTR_min_target') + 1)\n",
    "eCPM_comparison = (ws_headers['Stats by Creative'].index('eCPM') + 1, ws_headers['Stats by Creative'].index('eCPM_min_target') + 1)\n",
    "\n",
    "# Make CTR or eCPM orange if less than min target\n",
    "for stat_comparison in [ctr_comparison, eCPM_comparison]:\n",
    "    for row in stats_by_creative_sheet.iter_rows(min_row=2):\n",
    "        value_i = row[stat_comparison[0]-1].value\n",
    "        value_j = row[stat_comparison[1]-1].value\n",
    "\n",
    "        if value_i is not None and value_j is not None and value_i < value_j:\n",
    "            stats_by_creative_sheet.cell(row=row[0].row, column=stat_comparison[0]).fill = fills.PatternFill(patternType='solid', fgColor=Color(rgb='fce5cd'))\n",
    "            stats_by_creative_sheet.cell(row=row[0].row, column=stat_comparison[0]).border = thin_border\n",
    "\n",
    "\n",
    "# Make entire row orange if not sendable\n",
    "for row in stats_by_creative_sheet.iter_rows(min_row=2):\n",
    "    # If the Sendable column if False, make entire row orange\n",
    "    if not row[ws_headers['Stats by Creative'].index('Sendable')].value:\n",
    "        for cell in row:     \n",
    "            cell.fill = fills.PatternFill(patternType='solid', fgColor=Color(rgb='fce5cd'))\n",
    "            cell.border = thin_border\n",
    "\n",
    "    \n",
    "\n",
    "# wb.save(\"Content Request Report - {}.xlsx\".format(date.today().strftime(\"%m_%d_%Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04a8e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Worksheet \"Content Requests\">,\n",
       " <Worksheet \"Stats by Offer\">,\n",
       " <Worksheet \"Stats by Creative\">,\n",
       " <Worksheet \"Offer Inventory\">,\n",
       " <Worksheet \"Previous Script Requests\">]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81e295ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "today = date.today().strftime(\"%m_%d_%Y\")\n",
    "save_path = filepath.output_folder + \"Content Request Reports/\"\n",
    "filename = os.path.join(save_path, f\"Content_Request_Report_{today}.xlsx\")\n",
    "\n",
    "wb.save(filename)\n",
    "\n",
    "#filename = f\"Content_Feedback_Loop_Report_{today}.xlsx\"\n",
    "#wb.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "079af86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Data to Smartsheet...\n",
      "Data added to Smartsheet\n"
     ]
    }
   ],
   "source": [
    "# comment by Lili on 7/12\n",
    "#result = place_in_smartsheet(submission_df, key, sheet_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
