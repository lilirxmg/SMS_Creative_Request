{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ea257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsheets import Sheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import pygsheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import emoji\n",
    "import re\n",
    "import warnings\n",
    "import statistics\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import infrastructure \n",
    "from calendar import monthrange\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import xlsxwriter\n",
    "import send_email\n",
    "from colorama import Fore, Style\n",
    "import filepath\n",
    "import smartsheet\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08099154",
   "metadata": {},
   "source": [
    "# Downloading Lexi, Offers, CW, CT, and Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d38a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/4212767309.py:1: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lexi_original = pd.read_csv(filepath.output_folder + 'SS_LC_merged_data.csv')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID'] = mamba['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n"
     ]
    }
   ],
   "source": [
    "lexi_original = infrastructure.get_lexi()\n",
    "lexi = lexi_original.copy()\n",
    "lexi = lexi[lexi['Delivered']>0]\n",
    "lexi = infrastructure.transform_sms_df(lexi)\n",
    "\n",
    "lexi['eCPM'] = lexi['Revenue']*1000 / lexi['Delivered']\n",
    "lexi['CTR'] = lexi['Clicks'] / lexi['Delivered']\n",
    "lexi['Shortcode Name'] = lexi['Shortcode Name'].str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c746bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = infrastructure.get_lanina()\n",
    "cw.dropna(subset=['Reporting Content ID'],inplace=True)\n",
    "\n",
    "cw.dropna(subset=['OfferIDs'], inplace = True)\n",
    "mask = cw['Type (Pitch)'] == 'HOL'\n",
    "cw = cw[~mask]\n",
    "cw['Allocation Period (Date Added)'] = pd.to_datetime(cw['Allocation Period (Date Added)'], format='mixed')\n",
    "cw.dropna(subset=['Reporting Content ID'],inplace=True)\n",
    "cw['OfferIDs'] = cw['OfferIDs'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a67862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_original = infrastructure.get_smartsheet('offers_sms')\n",
    "offers = offers_original.copy()\n",
    "offers.dropna(subset=['Hitpath Offer ID'],inplace=True)\n",
    "offers['Hitpath Offer ID'] = offers['Hitpath Offer ID'].astype(int)\n",
    "offers = offers.loc[(offers['Hitpath Offer ID']>1000) & (offers['Hitpath Offer ID'].isna()==False)]\n",
    "offers['Hitpath Offer ID'] = offers['Hitpath Offer ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712e1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow = infrastructure.get_smartsheet('ow_sms')\n",
    "ow['Available Shortcode'] = ow['Available Shortcode'].apply(lambda x: x.split('\\n'))\n",
    "ow_status_dict = ow.set_index('Hitpath Offer ID')['Status'].to_dict()\n",
    "live_ow_shortcodes_dict = ow[ow['Status']=='Live'].set_index('Hitpath Offer ID')['Available Shortcode'].to_dict()\n",
    "not_live_ows = ow[~(ow['Status']=='Live')]['Hitpath Offer ID'].unique().tolist()\n",
    "ow_hitpath_list = ow['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53b88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexi = lexi.sort_values(by='Date')\n",
    "\n",
    "lexi_30 = lexi[(lexi['Date'].dt.date >= (date.today() + timedelta(days=-30)))].copy()\n",
    "lexi_90 = lexi[(lexi['Date'].dt.date >= (date.today() + timedelta(days=-90)))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495675fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/3074324814.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ct['Submission Date'] = pd.to_datetime(ct['Submission Date'])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/3074324814.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ct['Date Added to La Nina (Akshad)'] = pd.to_datetime(ct['Date Added to La Nina (Akshad)'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "ct =infrastructure.get_smartsheet('content_sms')\n",
    "ct['Submission Date'] = pd.to_datetime(ct['Submission Date'])\n",
    "ct['Date Added to La Nina (Akshad)'].replace(to_replace=r\"[a-zA-Z- ()]\", value=\"\", regex=True, inplace=True)\n",
    "ct['Date Added to La Nina (Akshad)'] = pd.to_datetime(ct['Date Added to La Nina (Akshad)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84196a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/2744609448.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID']=mamba['Dataset'].str.split('_').str[2]\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/2744609448.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba[['Limit','Offset']] = mamba[['Limit','Offset']].fillna(\"\")\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/2744609448.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Drop Number'] = mamba['Drop'].str.split(expand=True)[1].astype(int)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/2744609448.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Day of Week'] = mamba['Date'].dt.dayofweek\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_13320/2744609448.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba.rename(columns={\"Segment \": \"Segment\"},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "mamba = infrastructure.get_mamba()\n",
    "mamba['Affiliate ID']=mamba['Dataset'].str.split('_').str[2]\n",
    "mamba[['Limit','Offset']] = mamba[['Limit','Offset']].fillna(\"\")\n",
    "mamba['Drop Number'] = mamba['Drop'].str.split(expand=True)[1].astype(int)\n",
    "mamba['Day of Week'] = mamba['Date'].dt.dayofweek\n",
    "mamba.rename(columns={\"Segment \": \"Segment\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e0772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_hitpaths = offers[(offers['Status'].isin(['Live']))&(offers['Direct Traffic Accepted ']=='Yes')]['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8473ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_codes = ['MFA', 'N3G', \"FRH\",\"TCH\",\"THM\",\"UTL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9903a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cw = cw[cw['Type'].isin(tf_codes)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056a01d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79c8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_already_requested_tf_content():\n",
    "    \"\"\"\n",
    "    :return: a list of Hitpath Offer IDs that have had TF content requested within the past 3 weeks in the \n",
    "            SMS Creative Submission smartsheet.\n",
    "    \"\"\"\n",
    "    already_requested_content = ct.copy()\n",
    "    already_requested_content = already_requested_content[['Submission Date', 'Date Added to La Nina (Akshad)', '# of Pieces Requested Per Toll Free', 'Hitpath Offer ID', 'Request Type (Request)','Toll Free Abbreviations']]\n",
    "    already_requested_content = already_requested_content[already_requested_content['Request Type (Request)'].str.contains('Content', na=False) ]\n",
    "    # Any offer without a date in this column has not been added to La Nina, and should not be requested again\n",
    "    already_requested_content = already_requested_content[((pd.isna(already_requested_content['Date Added to La Nina (Akshad)']))&(already_requested_content['Submission Date']>=pd.Timestamp(date.today()-timedelta(30)))) | \n",
    "                                                          (already_requested_content['Date Added to La Nina (Akshad)']>=pd.Timestamp(date.today() - timedelta(21)))]\n",
    "    already_requested_content = already_requested_content[ already_requested_content['# of Pieces Requested Per Toll Free']>0]                                                      \n",
    "\n",
    "    return already_requested_content['Hitpath Offer ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c928253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_df():\n",
    "    \"\"\" Make a dataframe containing all possible Hitpath/TF Shortcode combos\"\"\"\n",
    "\n",
    "    # Combine eligible_hitpaths with Toll Free Shortcodes\n",
    "    base_index = pd.MultiIndex.from_product([eligible_hitpaths, tf_codes], names=['Hitpath Offer ID', 'Shortcode Name'])\n",
    "\n",
    "    base_df = pd.DataFrame(index=base_index)\n",
    "\n",
    "    return base_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a83ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CTR50s():\n",
    "    \"\"\"Calculates CTR50 for each Hitpath for all Lexi data\"\"\"\n",
    "    \n",
    "    CTR50s = lexi.groupby(['Hitpath Offer ID'])[['Clicks', 'Revenue', 'Delivered']].sum()\n",
    "    CTR50s['eCPM'] = 1000 * CTR50s['Revenue'] / CTR50s['Delivered']\n",
    "    CTR50s['CTR'] = CTR50s['Clicks'] / CTR50s['Delivered']\n",
    "    CTR50s['eCPM Normalized'] = (CTR50s['eCPM'] - CTR50s['eCPM'].min()) / (CTR50s['eCPM'].max() - CTR50s['eCPM'].min())\n",
    "    CTR50s['CTR Normalized'] = (CTR50s['CTR'] - CTR50s['CTR'].min()) / (CTR50s['CTR'].max() - CTR50s['CTR'].min())\n",
    "    CTR50s['CTR50'] = CTR50s['eCPM Normalized'] + CTR50s['CTR Normalized']\n",
    "\n",
    "    eCPM0_offers = []\n",
    "    for index, row in CTR50s.iterrows():\n",
    "        if row['eCPM'] == 0:\n",
    "            eCPM0_offers.append(index)\n",
    "\n",
    "    eCPM0_offers = pd.DataFrame(eCPM0_offers, columns=['Hitpath Offer ID'])\n",
    "    eCPM0_offers['Reason for Exclusion'] = 'Aggregate eCPM is $0'\n",
    "    \n",
    "    return CTR50s, eCPM0_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b466fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stats_by_dayrange(dayrange):\n",
    "    \"\"\"Creates statistics given the previous days you want to look at.\n",
    "    \n",
    "    :param dayrange: an int of the number of days in the past in Lexi you want to consider\n",
    "    :return: a DataFrame of lexi stats for each Hitpath in the number of days given\"\"\"\n",
    "    \n",
    "    shortened_lexi = lexi[(lexi['Date'].dt.date >= (date.today() - timedelta(days=dayrange)))].copy()\n",
    "    sum_stats = ['Revenue', 'Delivered', 'Optout', 'Clicks', 'Jump Page Clicks', 'Opportunity Cost']\n",
    "    stats_df = shortened_lexi.groupby(['Hitpath Offer ID', 'Shortcode Name'])[sum_stats].sum()\n",
    "    stats_df['eCPM'] = 1000 * stats_df['Revenue'] / stats_df['Delivered']\n",
    "    stats_df['OOR'] = stats_df['Optout'] / stats_df['Delivered']\n",
    "    stats_df['CTR'] = stats_df['Clicks'] / stats_df['Delivered']\n",
    "    stats_df['Jump Page CTR'] = stats_df['Jump Page Clicks'] / stats_df['Delivered']\n",
    "    stats_df['Opportunity Cost eCPM'] = 1000 * stats_df['Opportunity Cost'] / stats_df['Delivered']\n",
    "    stats_df['Engagement Ratio'] = stats_df['CTR'] / stats_df['OOR']\n",
    "    shortened_lexi = shortened_lexi[shortened_lexi['Creative Type'].isna() == False]\n",
    "    extra_info = shortened_lexi.groupby(['Hitpath Offer ID', 'Shortcode Name']).agg(Drops=('Date', 'count'), Max_Date=('Date', 'max'), Creative=('Creative Type', lambda x: x.value_counts().idxmax() if len(x)>0 else \"no Data\"), \n",
    "                                                                                    Creative_Drops=('Creative Type', lambda x: x.value_counts().max()))\n",
    "    extra_info = extra_info.rename(columns={'Drops':'Number of Drops', 'Max_Date':'Most Recent Drop', 'Creative':'Most Dropped Creative'})\n",
    "    extra_info['Top Creative Drop %'] = round(extra_info['Creative_Drops'] / extra_info['Number of Drops'], 4)\n",
    "    extra_info = extra_info.drop('Creative_Drops', axis=1)\n",
    "    stats_df = stats_df.merge(extra_info, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d3fd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_dfs(min_pieces=2):\n",
    "    \"\"\"Makes the DataFrames necessary for the report.\n",
    "    \n",
    "    :param min_pieces: an int of the number of Pieces you want to have for each hitpath. Default is 2\n",
    "    :return: 3 DataFrames. The first is a DataFrame of Hitpaths that need requests. The second is a DataFrame\n",
    "    of 30 day statistics for each Hitpath/Shortcode combo. The third is a DataFrame of hitpaths that were excluded from being requested despite\n",
    "    being eligible based on Offer smartsheet requirements \"\"\"\n",
    "\n",
    "    base_df = make_base_df()\n",
    "    base_df = base_df.reset_index(level=1)\n",
    "    CTR50s, eCPM0_offers = get_CTR50s()\n",
    "    already_requested_hitpaths = find_already_requested_tf_content()\n",
    "\n",
    "    eCPM0_offers = eCPM0_offers[eCPM0_offers['Hitpath Offer ID'].isin(eligible_hitpaths)]\n",
    "\n",
    "    hitpaths_to_exclude = eCPM0_offers['Hitpath Offer ID'].tolist()\n",
    "\n",
    "    # Merge CTR50 info onto base_df\n",
    "    base_df = base_df.merge(CTR50s, how='left', on='Hitpath Offer ID')\n",
    "    base_df = base_df.reset_index()\n",
    "    base_df = base_df.set_index(['Hitpath Offer ID', 'Shortcode Name'])\n",
    "\n",
    "    # Find how many content pieces there are currently for each offer\n",
    "    num_current_pieces = tf_cw.groupby(['OfferIDs', 'Type']).agg(num_current_pieces=('Reporting Content ID', 'count'))\n",
    "    num_current_pieces = num_current_pieces.rename(columns={'num_current_pieces':'Pieces in La Nina'})\n",
    "    num_current_pieces.index.names = ['Hitpath Offer ID', 'Shortcode Name']\n",
    "\n",
    "    # Show how many pieces currently in La Nina for each Hit/Shortcode combo\n",
    "    base_df = base_df.merge(num_current_pieces, how='left', left_index=True, right_index=True)    \n",
    "    # If N/A, not in La Nina, so value is 0\n",
    "    base_df['Pieces in La Nina'] = base_df['Pieces in La Nina'].fillna(0)\n",
    "    # Determine how many pieces to request\n",
    "    base_df['Pieces to Request'] = min_pieces - base_df['Pieces in La Nina']\n",
    "\n",
    "    # Get list of Hitpath Offer IDs that have any of their shortcodes needing more pieces\n",
    "    hitpaths_to_request = base_df[base_df['Pieces in La Nina'] < min_pieces].groupby(level='Hitpath Offer ID').any().index.tolist()\n",
    "\n",
    "    # Do not request any offers with $0 aggregate eCPM\n",
    "    hitpaths_to_request = [hitpath for hitpath in hitpaths_to_request if hitpath not in eCPM0_offers]\n",
    "\n",
    "    # Dataframe of only Hitpath Offer ID/Shortcode combos that need requests\n",
    "    need_request = base_df.loc[hitpaths_to_request].copy()\n",
    "    need_request['Pieces to Request'] = need_request.groupby(level='Hitpath Offer ID')['Pieces to Request'].transform('max')\n",
    "    need_request = need_request.sort_values(by=['CTR50', 'Pieces to Request'], ascending=[False, False])\n",
    "    need_request = need_request[['Pieces to Request', 'CTR50']]\n",
    "    need_request = need_request.reset_index()\n",
    "    need_request = need_request[~(need_request['Hitpath Offer ID'].isin(hitpaths_to_exclude))]\n",
    "    need_request = need_request[~(need_request['Hitpath Offer ID'].isin(already_requested_hitpaths))]\n",
    "    need_request = need_request.drop('Shortcode Name', axis=1)\n",
    "    need_request = need_request.drop_duplicates(subset='Hitpath Offer ID')\n",
    "\n",
    "    # Make df of stats\n",
    "    stats_30d = create_stats_by_dayrange(30)\n",
    "    # Merge 30d stats onto base df (just using Pieces in La Nina as placeholder)\n",
    "    tf_30d_stats = base_df[['Pieces in La Nina']].merge(stats_30d, how='left', left_index=True, right_index=True)\n",
    "    tf_30d_stats = tf_30d_stats[stats_30d.columns]\n",
    "    tf_30d_stats = tf_30d_stats.reset_index()\n",
    "    tf_30d_stats = tf_30d_stats.sort_values(by=['eCPM', 'Hitpath Offer ID'], ascending=[False, True])\n",
    "\n",
    "    # Make DataFrame of hitpaths that were excluded from being requested\n",
    "    already_requested_hitpaths_df = pd.DataFrame(already_requested_hitpaths, columns=['Hitpath Offer ID'])\n",
    "    already_requested_hitpaths_df['Reason for Exclusion'] = 'Hitpath already has TF content requested'\n",
    "    excluded_hitpath_requests = pd.concat([eCPM0_offers, already_requested_hitpaths_df])\n",
    "    excluded_hitpath_requests = excluded_hitpath_requests.merge(base_df['Pieces in La Nina'], how='left', on='Hitpath Offer ID')\n",
    "    excluded_hitpath_requests['Pieces in La Nina'] = excluded_hitpath_requests['Pieces in La Nina'].fillna(0)\n",
    "    excluded_hitpath_requests = excluded_hitpath_requests.drop_duplicates(subset=['Hitpath Offer ID', 'Reason for Exclusion'])\n",
    "    excluded_hitpath_requests = excluded_hitpath_requests.sort_values(by='Pieces in La Nina')\n",
    "\n",
    "    return need_request, tf_30d_stats, excluded_hitpath_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1363c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_number_to_letter(num_sheet_cols):\n",
    "    \"\"\"\n",
    "    Takes the 1-indexed number of a column in a google sheet and returns the letter version. For example,\n",
    "    if num_sheet_cols=1, it would return 'A'. If it was 27, it would return 'AA'. If it was 53, it would return 'BA'.\n",
    "\n",
    "    :param num_sheet_cols: an int of the column in the google sheet\n",
    "    :return: a string of the corresponding letter(s) of the column\n",
    "    \"\"\"\n",
    "    # One letter cases (A-Z)\n",
    "    if ((num_sheet_cols // 26) == 0) | (num_sheet_cols == 26):\n",
    "        letter = chr(64 + num_sheet_cols)\n",
    "\n",
    "    # Multiple letter cases (i.e. AA)\n",
    "    else:\n",
    "        # Z special case\n",
    "        if num_sheet_cols % 26 == 0:\n",
    "            first_letter = chr(64 + (num_sheet_cols // 26) - 1)\n",
    "            second_letter = chr(64 + num_sheet_cols - (((num_sheet_cols // 26) - 1) * 26))\n",
    "            letter = (first_letter + second_letter)\n",
    "        # All other letters\n",
    "        else:\n",
    "            first_letter = chr(64 + (num_sheet_cols // 26))\n",
    "            second_letter = chr(64 + num_sheet_cols - ((num_sheet_cols // 26) * 26))\n",
    "            letter = (first_letter + second_letter)\n",
    "\n",
    "    return letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d38255",
   "metadata": {},
   "source": [
    "# Make DataFrames and Save as Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53e642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_request, tf_30d_stats, excluded_hitpath_requests = make_final_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac3ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import flatten\n",
    "from openpyxl.styles import numbers\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Color, colors, fills\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from openpyxl.styles.borders import Border, Side, BORDER_THIN\n",
    "thin_border = Border(\n",
    "    left=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    right=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    top=Side(border_style=BORDER_THIN, color='D3D3D3'),\n",
    "    bottom=Side(border_style=BORDER_THIN, color='D3D3D3')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b34ff1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Recently Tested Content Report\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "all_sheets = []\n",
    "ws_headers = {}\n",
    "\n",
    "ws_headers['TF Content Requests'] = need_request.columns.tolist()\n",
    "ws_headers['30 Day TF Stats'] = tf_30d_stats.columns.tolist()\n",
    "ws_headers['Excluded Offers'] = excluded_hitpath_requests.columns.tolist()\n",
    "\n",
    "content_request_sheet = wb['Sheet']\n",
    "content_request_sheet.title = 'TF Content Requests'\n",
    "\n",
    "# Column names to format specially\n",
    "currency_format_cols = ['Revenue', 'Opportunity Cost', 'eCPM', 'Opportunity Cost eCPM']\n",
    "percent_format_cols = ['OOR', 'CTR', 'Jump Page CTR', 'Top Creative Drop %']\n",
    "comma_format_cols = ['Optout', 'Clicks', 'Jump Page Clicks', 'Delivered']\n",
    "\n",
    "for r in dataframe_to_rows(need_request, index=False, header=True):\n",
    "    content_request_sheet.append(r)\n",
    "all_sheets.append(content_request_sheet)\n",
    "\n",
    "tf_30d_stats_sheet = wb.create_sheet('30 Day TF Stats')\n",
    "for r in dataframe_to_rows(tf_30d_stats, index=False, header=True):\n",
    "    tf_30d_stats_sheet.append(r)\n",
    "all_sheets.append(tf_30d_stats_sheet)\n",
    "\n",
    "excluded_offers_sheet = wb.create_sheet('Excluded Offers')\n",
    "for r in dataframe_to_rows(excluded_hitpath_requests, index=False, header=True):\n",
    "    excluded_offers_sheet.append(r)\n",
    "all_sheets.append(excluded_offers_sheet)\n",
    "\n",
    "logic_and_definitions_sheet = wb.create_sheet('Logic and Definitions')\n",
    "logic_and_definitions_sheet.cell(1, 1).value = 'Logic:'\n",
    "logic_and_definitions_sheet.cell(1, 2).value = 'https://docs.google.com/document/d/1qULMVf6xEkUYNpf7t8FOCNIMSxoy_LQTL1L3VaPv-qk/edit?usp=sharing'\n",
    "logic_and_definitions_sheet.cell(2, 1).value = 'Definitions:'\n",
    "logic_and_definitions_sheet.cell(2, 2).value = 'https://docs.google.com/document/d/1al4IlJBpN3yN9_rD_TJuBnqHtWcjAI8ECBnuUw1Xiys/edit?usp=sharing'\n",
    "\n",
    "\n",
    "for ws in all_sheets:\n",
    "    dims = {}\n",
    "    headers = ws_headers[ws.title]\n",
    "\n",
    "    for row in ws.rows:\n",
    "        for cell in ws[\"1:1\"]:\n",
    "            cell.font = Font(bold=True)\n",
    "        for cell in row:\n",
    "            newline_count = 1\n",
    "            if cell.value:\n",
    "                if type(cell.value)==str:\n",
    "                    if ('\\n' in cell.value):\n",
    "                        newline_count = cell.value.count('\\n')\n",
    "                dims[cell.column_letter] = max((dims.get(cell.column_letter, 0), len(str(cell.value))))/newline_count \n",
    "    for col, value in dims.items():\n",
    "        ws.column_dimensions[col].width = value\n",
    "\n",
    "    for col in currency_format_cols:\n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_CURRENCY_USD_SIMPLE\n",
    "\n",
    "    for col in percent_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = numbers.FORMAT_PERCENTAGE_00\n",
    "\n",
    "    for col in comma_format_cols:    \n",
    "        if col in headers:    \n",
    "            col_num = headers.index(col) + 1\n",
    "            col_letter = convert_number_to_letter(col_num)\n",
    "            # Format column C as currency to 2 decimal places\n",
    "            for cell in ws[col_letter]:\n",
    "                cell.number_format = '#,##0'\n",
    "\n",
    "    ws.freeze_panes = 'A2'   \n",
    "save_path = filepath.output_folder + \"Content Request Reports/\"\n",
    "today = date.today().strftime(\"%m_%d_%Y\")\n",
    "filename = os.path.join(save_path, f\"TF Content Request Report - {today}.xlsx\")\n",
    "wb.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d188fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:49: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"metadata\": {},\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mamba['Affiliate ID'] = mamba['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"lexi_original = pd.read_csv(filepath.input_folder + 'SS_LC_merged_data.csv')\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:95: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"lexi = infrastructure.transform_sms_df(lexi)\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/infrastructure.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"# lexi.dropna(subset=['Hitpath Offer ID'], inplace = True)\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['eCPM'] = lexi['Revenue']*1000 / lexi['Delivered']\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['CTR'] = lexi['Clicks'] / lexi['Delivered']\\n\",\n",
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Creative_package/Content_Request_Report_SMS.ipynb:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"lexi['Hitpath Offer ID'] = lexi['Hitpath Offer ID'].astype(str)\\n\",\n",
      "/opt/anaconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hitpath ID Request ID High Priority Submission Date  Due Date   \\\n",
      "0      13498                    False      2024-07-15 2024-07-18   \n",
      "1      13349                    False      2024-07-15 2024-07-18   \n",
      "2      11600                    False      2024-07-15 2024-07-18   \n",
      "3      12710                    False      2024-07-15 2024-07-18   \n",
      "4      13519                    False      2024-07-15 2024-07-18   \n",
      "\n",
      "  Request Sent to Copywriter (Kellie)  \\\n",
      "0                                       \n",
      "1                                       \n",
      "2                                       \n",
      "3                                       \n",
      "4                                       \n",
      "\n",
      "  Unapproved Content Document Link (Copywriter)  \\\n",
      "0                                                 \n",
      "1                                                 \n",
      "2                                                 \n",
      "3                                                 \n",
      "4                                                 \n",
      "\n",
      "  Unapproved Jump Page Content (Copywriter) Image ID - Jump Page (Copywriter)  \\\n",
      "0                                                                               \n",
      "1                                                                               \n",
      "2                                                                               \n",
      "3                                                                               \n",
      "4                                                                               \n",
      "\n",
      "  Request Type (Request)  ... Requested By              RX Rep  \\\n",
      "0                Content  ...       Script          Haley Bush   \n",
      "1                Content  ...       Script   Rhiannon Selander   \n",
      "2                Content  ...       Script       Hartley Goode   \n",
      "3                Content  ...       Script       Hartley Goode   \n",
      "4                Content  ...       Script  Jennifer Sporleder   \n",
      "\n",
      "                      External AM Email Channel Platform # of Shortcodes  \\\n",
      "0              kristine.o@point2web.com      TF       SS               5   \n",
      "1            taylor@interest-media.com       TF       SS               5   \n",
      "2      Mike - mike@whatifmediagroup.com      TF       SS               5   \n",
      "3      Mike - mike@whatifmediagroup.com      TF       SS               5   \n",
      "4  Ryan Zimmerman (ryan@avenuelink.com)      TF       SS               5   \n",
      "\n",
      "  Total Requests per Hitpath 30D Drop Count 90D Drop Count Priority Order  \n",
      "0                         10           27.0           30.0            4.0  \n",
      "1                         10           43.0           46.0            5.0  \n",
      "2                         10          217.0          587.0            6.0  \n",
      "3                         10          129.0          362.0            7.0  \n",
      "4                          5           14.0           14.0            8.0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ipynb.fs.full.Content_Request_Report_SMS import *\n",
    "request_tf = ['MFA', 'N3G', \"FRH\",'DA','TRS']\n",
    "submission_df = finalize_submission_tf_df(need_request,request_tf )\n",
    "final_submission_df = make_pieces_request_tf_df(submission_df,request_tf, request_limit=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee5c16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Data to Smartsheet...\n",
      "Data added to Smartsheet\n"
     ]
    }
   ],
   "source": [
    "#sheet_id = 8253683024220036 # real sheet id \n",
    "sheet_id = 7853583898726276 # test sheet id \n",
    "key = 'wf3Jr9OaAT5OE8gE8yctPqfmzrv6dUFATUODD'\n",
    "#result = place_in_smartsheet(final_submission_df, key, sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e266b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hitpath ID</th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Due Date</th>\n",
       "      <th>Request Type (Request)</th>\n",
       "      <th>Creative Approval Status</th>\n",
       "      <th>Offer Type</th>\n",
       "      <th>Hitpath Offer ID</th>\n",
       "      <th>Offer Name</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Landing Page / Redirect Link</th>\n",
       "      <th>Compliance &amp; Additional Notes (Request)</th>\n",
       "      <th># of Pieces Requested Per Shortcode</th>\n",
       "      <th># of Pieces Requested Per Toll Free</th>\n",
       "      <th>Shortcode Abbreviations</th>\n",
       "      <th>Toll Free Abbreviations</th>\n",
       "      <th>Requested By</th>\n",
       "      <th>RX Rep</th>\n",
       "      <th>External AM Email</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13498</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>13498</td>\n",
       "      <td>McDonalds - US (SMS)  2039 - Point2Web</td>\n",
       "      <td>Sweepstakes</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=13498&amp;p...</td>\n",
       "      <td>Extra Content for direct traffic in Toll Free</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>MFA\\nN3G\\nFRH\\nDA\\nTRS</td>\n",
       "      <td>Script</td>\n",
       "      <td>Haley Bush</td>\n",
       "      <td>kristine.o@point2web.com</td>\n",
       "      <td>TF</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13349</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>13349</td>\n",
       "      <td>Trendn Daily - iphone 15</td>\n",
       "      <td>Sweepstakes</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=13349&amp;p...</td>\n",
       "      <td>Extra Content for direct traffic in Toll Free</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>MFA\\nN3G\\nFRH\\nDA\\nTRS</td>\n",
       "      <td>Script</td>\n",
       "      <td>Rhiannon Selander</td>\n",
       "      <td>taylor@interest-media.com</td>\n",
       "      <td>TF</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11600</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>11600</td>\n",
       "      <td>Unemployments Benefits Guide Stimulus Carousel...</td>\n",
       "      <td>Resources</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=11600&amp;p...</td>\n",
       "      <td>Extra Content for direct traffic in Toll Free</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>MFA\\nN3G\\nFRH\\nDA\\nTRS</td>\n",
       "      <td>Script</td>\n",
       "      <td>Hartley Goode</td>\n",
       "      <td>Mike - mike@whatifmediagroup.com</td>\n",
       "      <td>TF</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12710</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>12710</td>\n",
       "      <td>Unemployment Benefits Guide - State Stimulus -...</td>\n",
       "      <td>Resources</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=12710&amp;p...</td>\n",
       "      <td>Extra Content for direct traffic in Toll Free</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>MFA\\nN3G\\nFRH\\nDA\\nTRS</td>\n",
       "      <td>Script</td>\n",
       "      <td>Hartley Goode</td>\n",
       "      <td>Mike - mike@whatifmediagroup.com</td>\n",
       "      <td>TF</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13519</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Content</td>\n",
       "      <td>Yes - need advertiser approval</td>\n",
       "      <td>Existing - More Content</td>\n",
       "      <td>13519</td>\n",
       "      <td>Smart--Advances.com $1K - AvenueLink (SMS-OPS)</td>\n",
       "      <td>Loan</td>\n",
       "      <td>https://www.rentonion.com/rd/r.php?sid=13519&amp;p...</td>\n",
       "      <td>Extra Content for direct traffic in Toll Free</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>MFA\\nN3G\\nFRH\\nDA\\nTRS</td>\n",
       "      <td>Script</td>\n",
       "      <td>Jennifer Sporleder</td>\n",
       "      <td>Ryan Zimmerman (ryan@avenuelink.com)</td>\n",
       "      <td>TF</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hitpath ID Submission Date   Due Date  Request Type (Request)  \\\n",
       "0      13498      2024-07-15  2024-07-18                Content   \n",
       "1      13349      2024-07-15  2024-07-19                Content   \n",
       "2      11600      2024-07-15  2024-07-19                Content   \n",
       "3      12710      2024-07-15  2024-07-22                Content   \n",
       "4      13519      2024-07-15  2024-07-22                Content   \n",
       "\n",
       "         Creative Approval Status               Offer Type  Hitpath Offer ID  \\\n",
       "0  Yes - need advertiser approval  Existing - More Content             13498   \n",
       "1  Yes - need advertiser approval  Existing - More Content             13349   \n",
       "2  Yes - need advertiser approval  Existing - More Content             11600   \n",
       "3  Yes - need advertiser approval  Existing - More Content             12710   \n",
       "4  Yes - need advertiser approval  Existing - More Content             13519   \n",
       "\n",
       "                                          Offer Name     Vertical  \\\n",
       "0             McDonalds - US (SMS)  2039 - Point2Web  Sweepstakes   \n",
       "1                           Trendn Daily - iphone 15  Sweepstakes   \n",
       "2  Unemployments Benefits Guide Stimulus Carousel...    Resources   \n",
       "3  Unemployment Benefits Guide - State Stimulus -...    Resources   \n",
       "4     Smart--Advances.com $1K - AvenueLink (SMS-OPS)         Loan   \n",
       "\n",
       "                        Landing Page / Redirect Link  \\\n",
       "0  https://www.rentonion.com/rd/r.php?sid=13498&p...   \n",
       "1  https://www.rentonion.com/rd/r.php?sid=13349&p...   \n",
       "2  https://www.rentonion.com/rd/r.php?sid=11600&p...   \n",
       "3  https://www.rentonion.com/rd/r.php?sid=12710&p...   \n",
       "4  https://www.rentonion.com/rd/r.php?sid=13519&p...   \n",
       "\n",
       "         Compliance & Additional Notes (Request)  \\\n",
       "0  Extra Content for direct traffic in Toll Free   \n",
       "1  Extra Content for direct traffic in Toll Free   \n",
       "2  Extra Content for direct traffic in Toll Free   \n",
       "3  Extra Content for direct traffic in Toll Free   \n",
       "4  Extra Content for direct traffic in Toll Free   \n",
       "\n",
       "   # of Pieces Requested Per Shortcode  # of Pieces Requested Per Toll Free  \\\n",
       "0                                    0                                    2   \n",
       "1                                    0                                    2   \n",
       "2                                    0                                    2   \n",
       "3                                    0                                    2   \n",
       "4                                    0                                    1   \n",
       "\n",
       "  Shortcode Abbreviations Toll Free Abbreviations Requested By  \\\n",
       "0                          MFA\\nN3G\\nFRH\\nDA\\nTRS       Script   \n",
       "1                          MFA\\nN3G\\nFRH\\nDA\\nTRS       Script   \n",
       "2                          MFA\\nN3G\\nFRH\\nDA\\nTRS       Script   \n",
       "3                          MFA\\nN3G\\nFRH\\nDA\\nTRS       Script   \n",
       "4                          MFA\\nN3G\\nFRH\\nDA\\nTRS       Script   \n",
       "\n",
       "               RX Rep                     External AM Email Channel Platform  \n",
       "0          Haley Bush              kristine.o@point2web.com      TF       SS  \n",
       "1   Rhiannon Selander            taylor@interest-media.com       TF       SS  \n",
       "2       Hartley Goode      Mike - mike@whatifmediagroup.com      TF       SS  \n",
       "3       Hartley Goode      Mike - mike@whatifmediagroup.com      TF       SS  \n",
       "4  Jennifer Sporleder  Ryan Zimmerman (ryan@avenuelink.com)      TF       SS  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70eeed",
   "metadata": {},
   "source": [
    "# Send Email out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f1d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ntoaddr = [\\'offernotices@rxmg.com\\', \\'nathan@rxmg.com\\',\\'nina@rxmg.com\\', \\'k.smith@rxmg.com\\', \\'a.miller@rxmg.com\\',  \\'lili@rxmg.com\\', \\'r.woodward@rxmg.com\\', \\'b.ratzlaff@rxmg.com\\']\\nsubject_line = f\"SMS Content Request Report - {today}\"\\nemail_body = \"Hi Team,\\n\\n\"\\nemail_body += \"Please find this week\\'s Content Request Report attached.\\n\\n\" \\nemail_body += \"The following AMs have offer content that was requested:\\n\" \\nfor key, value in rx_rep_offer_dict.items():\\n    if value == 1:\\n        email_body += f\"\\t{key}: {value} offer\\n\"\\n    else:\\n        email_body += f\"\\t{key}: {value} offers\\n\"\\nemail_body += f\"\\nThanks,\\n{filepath.name}\\n\\n\"\\n\\n#send email\\nfor i in toaddr:\\n    send_email.send_email([filename], subject_line, email_body, i)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#email\n",
    "\"\"\" \n",
    "toaddr = ['offernotices@rxmg.com', 'nathan@rxmg.com','nina@rxmg.com', 'k.smith@rxmg.com', 'a.miller@rxmg.com',  'lili@rxmg.com', 'r.woodward@rxmg.com', 'b.ratzlaff@rxmg.com']\n",
    "subject_line = f\"SMS Content Request Report - {today}\"\n",
    "email_body = \"Hi Team,\\n\\n\"\n",
    "email_body += \"Please find this week's Content Request Report attached.\\n\\n\" \n",
    "email_body += \"The following AMs have offer content that was requested:\\n\" \n",
    "for key, value in rx_rep_offer_dict.items():\n",
    "    if value == 1:\n",
    "        email_body += f\"\\t{key}: {value} offer\\n\"\n",
    "    else:\n",
    "        email_body += f\"\\t{key}: {value} offers\\n\"\n",
    "email_body += f\"\\nThanks,\\n{filepath.name}\\n\\n\"\n",
    "\n",
    "#send email\n",
    "for i in toaddr:\n",
    "    send_email.send_email([filename], subject_line, email_body, i)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
